{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and training-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "0           0  7129300520  20141013T000000  221900.0         3       1.00   \n",
      "1           1  6414100192  20141209T000000  538000.0         3       2.25   \n",
      "2           2  5631500400  20150225T000000  180000.0         2       1.00   \n",
      "3           3  2487200875  20141209T000000  604000.0         4       3.00   \n",
      "4           4  1954400510  20150218T000000  510000.0         3       2.00   \n",
      "\n",
      "   sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "0         1180      5650     1.0           0  ...      1955             0   \n",
      "1         2570      7242     2.0           0  ...      1951          1991   \n",
      "2          770     10000     1.0           0  ...      1933             0   \n",
      "3         1960      5000     1.0           0  ...      1965             0   \n",
      "4         1680      8080     1.0           0  ...      1987             0   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "0    98178  47.5112 -122.257           1340        5650  2014-10-13   \n",
      "1    98125  47.7210 -122.319           1690        7639  2014-12-09   \n",
      "2    98028  47.7379 -122.233           2720        8062  2015-02-25   \n",
      "3    98136  47.5208 -122.393           1360        5000  2014-12-09   \n",
      "4    98074  47.6168 -122.045           1800        7503  2015-02-18   \n",
      "\n",
      "   most_recent  price_range  \n",
      "0         1955            0  \n",
      "1         1991            0  \n",
      "2         1933            0  \n",
      "3         1965            1  \n",
      "4         1987            0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "       Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "21608       21608   263000018  20140521T000000  360000.0         3       2.50   \n",
      "21609       21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
      "21610       21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
      "21611       21611   291310100  20150116T000000  400000.0         3       2.50   \n",
      "21612       21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
      "\n",
      "       sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "21608         1530      1131     3.0           0  ...      2009             0   \n",
      "21609         2310      5813     2.0           0  ...      2014             0   \n",
      "21610         1020      1350     2.0           0  ...      2009             0   \n",
      "21611         1600      2388     2.0           0  ...      2004             0   \n",
      "21612         1020      1076     2.0           0  ...      2008             0   \n",
      "\n",
      "       zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "21608    98103  47.6993 -122.346           1530        1509  2014-05-21   \n",
      "21609    98146  47.5107 -122.362           1830        7200  2015-02-23   \n",
      "21610    98144  47.5944 -122.299           1020        2007  2014-06-23   \n",
      "21611    98027  47.5345 -122.069           1410        1287  2015-01-16   \n",
      "21612    98144  47.5941 -122.299           1020        1357  2014-10-15   \n",
      "\n",
      "       most_recent  price_range  \n",
      "21608         2009            0  \n",
      "21609         2014            0  \n",
      "21610         2009            0  \n",
      "21611         2004            0  \n",
      "21612         2008            0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read data from CSV file to dataframe\n",
    "df = pd.read_csv(r\"./input/kc_sales_cleaned.csv\")\n",
    "\n",
    "# make sure you understand the type of the object\n",
    "print(type(df))\n",
    "\n",
    "# check the top five and the botoom five data tuples\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Under', 'Over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.83      0.83      1360\n",
      "        Over       0.71      0.69      0.70       802\n",
      "\n",
      "    accuracy                           0.78      2162\n",
      "   macro avg       0.76      0.76      0.76      2162\n",
      "weighted avg       0.78      0.78      0.78      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.84      0.82      1355\n",
      "        Over       0.70      0.66      0.68       807\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.75      0.75      2162\n",
      "weighted avg       0.77      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.82      1348\n",
      "        Over       0.70      0.66      0.68       814\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.75      0.75      2162\n",
      "weighted avg       0.76      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.82      1367\n",
      "        Over       0.69      0.65      0.67       794\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.74      0.74      2161\n",
      "weighted avg       0.76      0.77      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1408\n",
      "        Over       0.66      0.66      0.66       753\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.74      0.74      0.74      2161\n",
      "weighted avg       0.76      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.84      0.83      1370\n",
      "        Over       0.70      0.67      0.69       791\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.76      0.76      2161\n",
      "weighted avg       0.78      0.78      0.78      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.81      0.82      1394\n",
      "        Over       0.67      0.69      0.68       767\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.81      1355\n",
      "        Over       0.69      0.66      0.68       806\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.75      0.74      0.75      2161\n",
      "weighted avg       0.76      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.83      0.81      1349\n",
      "        Over       0.69      0.64      0.67       812\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.74      0.73      0.74      2161\n",
      "weighted avg       0.75      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1388\n",
      "        Over       0.68      0.68      0.68       773\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "Average precision (ENTROPY): 0.7506297917950204\n",
      "Average recall (ENTROPY): 0.7466249810985011\n",
      "Average accuracy (ENTROPY): 0.768194543674533\n"
     ]
    }
   ],
   "source": [
    "# Entropy\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "# decision tree classifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='entropy', random_state=42)\n",
    "\n",
    "# k-fold cross validation (k=10)\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 2 folds\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "\n",
    "# each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"macro avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"macro avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Average precision (ENTROPY):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Average recall (ENTROPY):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Average accuracy (ENTROPY):\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.86      0.84      1368\n",
      "        Over       0.74      0.66      0.70       794\n",
      "\n",
      "    accuracy                           0.79      2162\n",
      "   macro avg       0.78      0.76      0.77      2162\n",
      "weighted avg       0.79      0.79      0.79      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.84      0.82      1378\n",
      "        Over       0.70      0.63      0.66       784\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.74      0.74      2162\n",
      "weighted avg       0.76      0.77      0.76      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.81      0.80      1339\n",
      "        Over       0.68      0.64      0.66       823\n",
      "\n",
      "    accuracy                           0.75      2162\n",
      "   macro avg       0.73      0.73      0.73      2162\n",
      "weighted avg       0.75      0.75      0.75      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.81      0.83      0.82      1361\n",
      "        Over       0.70      0.68      0.69       800\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.75      0.76      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1372\n",
      "        Over       0.69      0.68      0.68       789\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.85      0.82      1370\n",
      "        Over       0.70      0.63      0.66       791\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.74      0.74      2161\n",
      "weighted avg       0.76      0.77      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.81      0.81      1411\n",
      "        Over       0.64      0.66      0.65       750\n",
      "\n",
      "    accuracy                           0.75      2161\n",
      "   macro avg       0.73      0.73      0.73      2161\n",
      "weighted avg       0.76      0.75      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1348\n",
      "        Over       0.73      0.61      0.67       813\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.86      0.83      1381\n",
      "        Over       0.71      0.62      0.66       780\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.86      0.83      1366\n",
      "        Over       0.73      0.63      0.67       795\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.78      0.77      2161\n",
      "\n",
      "Average precision (GINI): 0.7527015625819437\n",
      "Average recall (GINI): 0.7428066335756423\n",
      "Average accuracy (GINI): 0.7688892446665105\n"
     ]
    }
   ],
   "source": [
    "# Gini\n",
    "\n",
    "# Construct a decision tree using gini index\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='gini', random_state=42)\n",
    "\n",
    "# 10-fold CV\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) \n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"macro avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"macro avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Average precision (GINI):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Average recall (GINI):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Average accuracy (GINI):\", accuracy_sum/kf.get_n_splits(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance information for gini classifier on max depth =  3 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.83      0.84      0.83      2726\n",
      "        Over       0.72      0.70      0.71      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.77      0.77      0.77      4323\n",
      "weighted avg       0.79      0.79      0.79      4323\n",
      "\n",
      "Precision (GINI): 0.7715737156931738\n",
      "Recall (GINI): 0.7694788145968849\n",
      "Accuracy (GINI): 0.7869535045107564\n",
      "\n",
      "Performance information for entropy classifier on max depth =  3 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.84      0.81      0.83      2726\n",
      "        Over       0.69      0.74      0.72      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.78      0.77      4323\n",
      "weighted avg       0.79      0.78      0.79      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7688380414160795\n",
      "Recall (ENTROPY): 0.7757599653789593\n",
      "Accuracy (ENTROPY): 0.7844089752486699\n",
      "\n",
      "Performance information for gini classifier on max depth =  4 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.90      0.84      2726\n",
      "        Over       0.78      0.59      0.67      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (GINI): 0.784653704893585\n",
      "Recall (GINI): 0.7472834014253615\n",
      "Accuracy (GINI): 0.7874161461947722\n",
      "\n",
      "Performance information for entropy classifier on max depth =  4 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.90      0.84      2726\n",
      "        Over       0.78      0.60      0.68      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.79      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7861806827314528\n",
      "Recall (ENTROPY): 0.7494750106927378\n",
      "Accuracy (ENTROPY): 0.7890353920888272\n",
      "\n",
      "Performance information for gini classifier on max depth =  5 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.88      0.84      2726\n",
      "        Over       0.76      0.63      0.69      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (GINI): 0.7792928075916197\n",
      "Recall (GINI): 0.754522649079276\n",
      "Accuracy (GINI): 0.7878787878787878\n",
      "\n",
      "Performance information for entropy classifier on max depth =  5 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.87      0.84      2726\n",
      "        Over       0.74      0.67      0.70      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.77      0.77      4323\n",
      "weighted avg       0.79      0.79      0.79      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7800784522996014\n",
      "Recall (ENTROPY): 0.7664360358357173\n",
      "Accuracy (ENTROPY): 0.7922738838769373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Change max depth and observe results \n",
    "\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)\n",
    "\n",
    "for i in [3,4,5]:\n",
    "    tree_clf_gini = DecisionTreeClassifier(max_depth= i, criterion=\"gini\", random_state=42)\n",
    "    tree_clf_entropy = DecisionTreeClassifier(max_depth = i, criterion=\"entropy\", random_state=42)\n",
    "    \n",
    "    tree_clf_gini.fit(X_train, y_train)\n",
    "    tree_clf_entropy.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_gini = tree_clf_gini.predict(X_test)\n",
    "    \n",
    "    y_pred_entropy = tree_clf_entropy.predict(X_test)    \n",
    "    \n",
    "    print(\"Performance information for gini classifier on max depth = \", i, \":\")\n",
    "    print()\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_gini, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict_gini = classification_report(y_test, y_pred_gini, target_names=target_names, output_dict=True)\n",
    "    print(\"Precision (GINI):\", result_metrics_dict_gini[\"macro avg\"][\"precision\"])\n",
    "    print(\"Recall (GINI):\", result_metrics_dict_gini[\"macro avg\"][\"recall\"])\n",
    "    print(\"Accuracy (GINI):\", result_metrics_dict_gini[\"accuracy\"])\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance information for entropy classifier on max depth = \", i, \":\")\n",
    "    print()\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_entropy, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict_entropy = classification_report(y_test, y_pred_entropy, target_names=target_names, output_dict=True)\n",
    "    print(\"Precision (ENTROPY):\", result_metrics_dict_entropy[\"macro avg\"][\"precision\"])\n",
    "    print(\"Recall (ENTROPY):\", result_metrics_dict_entropy[\"macro avg\"][\"recall\"])\n",
    "    print(\"Accuracy (ENTROPY):\", result_metrics_dict_entropy[\"accuracy\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for K =  3 \n",
      "\n",
      "Average precision (GINI): 0.7842357101370668\n",
      "Average recall (GINI): 0.7543143091297481\n",
      "Average accuracy (GINI): 0.7910518779052375 \n",
      "\n",
      "Average precision (ENTROPY): 0.7784626818032855\n",
      "Average recall (ENTROPY): 0.7620881182030738\n",
      "Average accuracy (ENTROPY): 0.7905891077809986 \n",
      "\n",
      "Results for K =  5 \n",
      "\n",
      "Average precision (GINI): 0.7813917596216193\n",
      "Average recall (GINI): 0.7533246051759319\n",
      "Average accuracy (GINI): 0.7894326195356607 \n",
      "\n",
      "Average precision (ENTROPY): 0.7783766143806481\n",
      "Average recall (ENTROPY): 0.7572549110496708\n",
      "Average accuracy (ENTROPY): 0.7886458717686132 \n",
      "\n",
      "Results for K =  7 \n",
      "\n",
      "Average precision (GINI): 0.7791384270824023\n",
      "Average recall (GINI): 0.7519252266027997\n",
      "Average accuracy (GINI): 0.7874887874151459 \n",
      "\n",
      "Average precision (ENTROPY): 0.7776391119890638\n",
      "Average recall (ENTROPY): 0.7586305424816775\n",
      "Average accuracy (ENTROPY): 0.7888305360916352 \n",
      "\n",
      "Results for K =  10 \n",
      "\n",
      "Average precision (GINI): 0.7787629914134627\n",
      "Average recall (GINI): 0.7540267001654275\n",
      "Average accuracy (GINI): 0.7880897424317468 \n",
      "\n",
      "Average precision (ENTROPY): 0.777115373088708\n",
      "Average recall (ENTROPY): 0.7562798880279982\n",
      "Average accuracy (ENTROPY): 0.7874883403159447 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change k value and observe results\n",
    "\n",
    "for k in [3,5,7,10]:\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    precision_sum_gini = recall_sum_gini = accuracy_sum_gini = 0\n",
    "    precision_sum_entropy = recall_sum_entropy = accuracy_sum_entropy = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        tree_clf_gini = DecisionTreeClassifier(max_depth= i, criterion=\"gini\", random_state=42)\n",
    "        tree_clf_entropy = DecisionTreeClassifier(max_depth = i, criterion=\"entropy\", random_state=42)\n",
    "    \n",
    "        tree_clf_gini.fit(X_train, y_train)\n",
    "        tree_clf_entropy.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred_gini = tree_clf_gini.predict(X_test)\n",
    "        y_pred_entropy = tree_clf_entropy.predict(X_test)  \n",
    "        \n",
    "    \n",
    "        result_metrics_dict_gini = classification_report(y_test, y_pred_gini, target_names=target_names, output_dict=True)\n",
    "        result_metrics_dict_entropy = classification_report(y_test, y_pred_entropy, target_names=target_names, output_dict=True)\n",
    "    \n",
    "        precision_sum_gini += result_metrics_dict_gini[\"macro avg\"][\"precision\"]\n",
    "        recall_sum_gini += result_metrics_dict_gini[\"macro avg\"][\"recall\"]\n",
    "        accuracy_sum_gini += result_metrics_dict_gini[\"accuracy\"]\n",
    "        \n",
    "        precision_sum_entropy += result_metrics_dict_entropy[\"macro avg\"][\"precision\"]\n",
    "        recall_sum_entropy += result_metrics_dict_entropy[\"macro avg\"][\"recall\"]\n",
    "        accuracy_sum_entropy += result_metrics_dict_entropy[\"accuracy\"]\n",
    "        \n",
    "    print(\"Results for K = \", k, \"\\n\")\n",
    "    \n",
    "    print(\"Average precision (GINI):\", precision_sum_gini/kf.get_n_splits(X))\n",
    "    print(\"Average recall (GINI):\", recall_sum_gini/kf.get_n_splits(X))\n",
    "    print(\"Average accuracy (GINI):\", accuracy_sum_gini/kf.get_n_splits(X), \"\\n\")\n",
    "    \n",
    "    print(\"Average precision (ENTROPY):\", precision_sum_entropy/kf.get_n_splits(X))\n",
    "    print(\"Average recall (ENTROPY):\", recall_sum_entropy/kf.get_n_splits(X))\n",
    "    print(\"Average accuracy (ENTROPY):\", accuracy_sum_entropy/kf.get_n_splits(X), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The performance of the gini and entropy classifiers was actually fairly similar on the same testing set, and the best performing depth appeared to be max depth = 3. Changing the value of K didn't change the results significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot important features\n",
    "def plot_feature_importances(clf, feature_names):\n",
    "    c_features = len(feature_names)\n",
    "    plt.barh(range(c_features), clf.feature_importances_)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature name\")\n",
    "    plt.yticks(np.arange(c_features), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DT classifier on training set: 1.00\n",
      "Accuracy of DT classifier on test set: 0.74\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Find the important features of the entropy DT model\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf1.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf1.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=60)\n",
    "\n",
    "# call the function above\n",
    "plot_feature_importances(clf1, X.columns.values.tolist())\n",
    "plt.show()\n",
    "\n",
    "print('Feature importances: {}'.format(tree_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will consider entropy Decision Tree with max depth = 3 and K = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1\n",
      "[[2179  547]\n",
      " [ 634  963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.77      0.80      0.79      2726\n",
      "        Over       0.64      0.60      0.62      1597\n",
      "\n",
      "    accuracy                           0.73      4323\n",
      "   macro avg       0.71      0.70      0.70      4323\n",
      "weighted avg       0.72      0.73      0.73      4323\n",
      "\n",
      "k=5\n",
      "[[2355  371]\n",
      " [ 617  980]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.86      0.83      2726\n",
      "        Over       0.73      0.61      0.66      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.76      0.74      0.75      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=15\n",
      "[[2364  362]\n",
      " [ 615  982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      2726\n",
      "        Over       0.73      0.61      0.67      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.76      0.74      0.75      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=20\n",
      "[[2422  304]\n",
      " [ 675  922]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.89      0.83      2726\n",
      "        Over       0.75      0.58      0.65      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.77      0.73      0.74      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=25\n",
      "[[2389  337]\n",
      " [ 619  978]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.88      0.83      2726\n",
      "        Over       0.74      0.61      0.67      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.74      0.75      4323\n",
      "weighted avg       0.78      0.78      0.77      4323\n",
      "\n",
      "k=30\n",
      "[[2417  309]\n",
      " [ 658  939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.89      0.83      2726\n",
      "        Over       0.75      0.59      0.66      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.74      0.75      4323\n",
      "weighted avg       0.77      0.78      0.77      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the best k value\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_value = [1, 5, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_value:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(f\"k={k}\")\n",
    "    \n",
    "    # plot a confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_mat)\n",
    "    \n",
    "    # Print classification report\n",
    "    target_names = ['Under', 'Over']\n",
    "   \n",
    "    #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    result_metrics = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    print(result_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Performance with k = 1 *******\n",
      "Precision:  0.7223142849111975\n",
      "Recall:  0.7227132213668531\n",
      "Accuracy:  0.7227132213668531\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 3 *******\n",
      "Precision:  0.7511881853068534\n",
      "Recall:  0.7540831468060191\n",
      "Accuracy:  0.7540831468060191\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 5 *******\n",
      "Precision:  0.7602495682267002\n",
      "Recall:  0.7638456120260123\n",
      "Accuracy:  0.7638456120260123\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 10 *******\n",
      "Precision:  0.7648813509063372\n",
      "Recall:  0.7683338207639805\n",
      "Accuracy:  0.7683338207639805\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 15 *******\n",
      "Precision:  0.7684567991363468\n",
      "Recall:  0.7722666603987838\n",
      "Accuracy:  0.7722666603987838\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 20 *******\n",
      "Precision:  0.769176734786725\n",
      "Recall:  0.7728220102359152\n",
      "Accuracy:  0.7728220102359152\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 25 *******\n",
      "Precision:  0.7699248850820828\n",
      "Recall:  0.773747550484393\n",
      "Accuracy:  0.773747550484393\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 30 *******\n",
      "Precision:  0.7692727312506377\n",
      "Recall:  0.7729144422425508\n",
      "Accuracy:  0.7729144422425508\n",
      "**************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-Cross validation (k=3) on the original data\n",
    "# KNN classifier with varying k values\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into k folds \n",
    "\n",
    "k_values = [1, 3, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_values:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "        \n",
    "        #print(f\"k={k}\")\n",
    "        #print(\"training score: \", knn.score(X_train, y_train))\n",
    "        #print(\"testing score: \", knn.score(X_test, y_test))\n",
    "    \n",
    "        # plot a confusion matrix\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "        #print(confusion_mat)\n",
    "    \n",
    "        #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        results = classification_report(y_test, y_pred, target_names=target_names)\n",
    "        #print(results)\n",
    "\n",
    "        metrics_dict = classification_report(y_test, y_pred, \n",
    "                        target_names=target_names, output_dict=True)\n",
    "\n",
    "        avg_precision = metrics_dict['weighted avg']['precision']\n",
    "        #print('precision (weighted):', avg_precision)\n",
    "        precision.append(avg_precision)\n",
    "    \n",
    "        avg_recall = metrics_dict['weighted avg']['recall']\n",
    "        #print('recall avg (weighted):', avg_recall)\n",
    "        recall.append(avg_recall)\n",
    "    \n",
    "        avg_accuracy = metrics_dict['accuracy']\n",
    "        #print('accuracy: ', avg_accuracy)\n",
    "        accuracy.append(avg_accuracy)\n",
    "        \n",
    "    print('\\n******* Performance with k =', k, '*******')\n",
    "    print('Precision: ', sum(precision)/len(precision))\n",
    "    print('Recall: ', sum(recall)/len(recall))\n",
    "    print('Accuracy: ', sum(accuracy)/len(accuracy))\n",
    "    print('**************************************\\n')\n",
    "    \n",
    "    plt.plot(k, np.mean(test_score), 'bo')\n",
    "    plt.plot(k, np.mean(train_score), 'rx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 30 is best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  most_recent\n",
      "0         3       1.00         1180      5650         1955\n",
      "1         3       2.25         2570      7242         1991\n",
      "2         2       1.00          770     10000         1933\n",
      "3         4       3.00         1960      5000         1965\n",
      "4         3       2.00         1680      8080         1987\n",
      "   bedrooms  bathrooms  sqft_living  sqft_lot  most_recent\n",
      "0  0.090909    0.12500     0.067170  0.003108     0.478261\n",
      "1  0.090909    0.28125     0.172075  0.004072     0.791304\n",
      "2  0.060606    0.12500     0.036226  0.005743     0.286957\n",
      "3  0.121212    0.37500     0.126038  0.002714     0.565217\n",
      "4  0.090909    0.25000     0.104906  0.004579     0.756522\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "print(data.head())\n",
    "\n",
    "# normalized\n",
    "min_max = preprocessing.MinMaxScaler()\n",
    "\n",
    "col = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']\n",
    "normData = min_max.fit_transform(data)\n",
    "\n",
    "normData = pd.DataFrame(normData, columns = col)\n",
    "print(normData.head())\n",
    "\n",
    "X_normalized = normData.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Performance with k = 1 *******\n",
      "Precision:  0.7192233709132082\n",
      "Recall:  0.719798174170851\n",
      "Accuracy:  0.719798174170851\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 3 *******\n",
      "Precision:  0.7497055512989208\n",
      "Recall:  0.7528339050849869\n",
      "Accuracy:  0.7528339050849869\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 5 *******\n",
      "Precision:  0.7635897619206857\n",
      "Recall:  0.7671307918352605\n",
      "Accuracy:  0.7671307918352605\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 10 *******\n",
      "Precision:  0.7668028331983016\n",
      "Recall:  0.7701847920867465\n",
      "Accuracy:  0.7701847920867465\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 15 *******\n",
      "Precision:  0.7709354430588234\n",
      "Recall:  0.7747187897642904\n",
      "Accuracy:  0.7747187897642904\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 20 *******\n",
      "Precision:  0.7681464613833189\n",
      "Recall:  0.7718040122927569\n",
      "Accuracy:  0.7718040122927569\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 25 *******\n",
      "Precision:  0.7720678326921595\n",
      "Recall:  0.7757831032519394\n",
      "Accuracy:  0.7757831032519394\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 30 *******\n",
      "Precision:  0.7706789236262731\n",
      "Recall:  0.7743489011874685\n",
      "Accuracy:  0.7743489011874685\n",
      "**************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-Cross Validation on the normalized data\n",
    "# KNN classifier with varying k values\n",
    "\n",
    "k_values = [1, 3, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_values:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X_normalized):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "        \n",
    "        #print(f\"k={k}\")\n",
    "        #print(\"training score: \", knn.score(X_train, y_train))\n",
    "        #print(\"testing score: \", knn.score(X_test, y_test))\n",
    "    \n",
    "        # plot a confusion matrix\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "        #print(confusion_mat)\n",
    "    \n",
    "        #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        results = classification_report(y_test, y_pred, target_names=target_names)\n",
    "        #print(results)\n",
    "\n",
    "        metrics_dict = classification_report(y_test, y_pred, \n",
    "                        target_names=target_names, output_dict=True)\n",
    "\n",
    "        avg_precision = metrics_dict['weighted avg']['precision']\n",
    "        #print('precision (weighted):', avg_precision)\n",
    "        precision.append(avg_precision)\n",
    "    \n",
    "        avg_recall = metrics_dict['weighted avg']['recall']\n",
    "        #print('recall avg (weighted):', avg_recall)\n",
    "        recall.append(avg_recall)\n",
    "    \n",
    "        avg_accuracy = metrics_dict['accuracy']\n",
    "        #print('accuracy: ', avg_accuracy)\n",
    "        accuracy.append(avg_accuracy)\n",
    "        \n",
    "    print('\\n******* Performance with k =', k, '*******')\n",
    "    print('Precision: ', sum(precision)/len(precision))\n",
    "    print('Recall: ', sum(recall)/len(recall))\n",
    "    print('Accuracy: ', sum(accuracy)/len(accuracy))\n",
    "    print('**************************************\\n')\n",
    "    \n",
    "    plt.plot(k, np.mean(test_score), 'bo')\n",
    "    plt.plot(k, np.mean(train_score), 'rx')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized vs non-normalized data does not change much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.88      0.83      1379\n",
      "        Over       0.74      0.60      0.66       783\n",
      "\n",
      "    accuracy                           0.78      2162\n",
      "   macro avg       0.77      0.74      0.75      2162\n",
      "weighted avg       0.77      0.78      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1383\n",
      "        Over       0.73      0.60      0.66       779\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.76      0.74      0.74      2162\n",
      "weighted avg       0.77      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.88      0.83      1354\n",
      "        Over       0.75      0.59      0.66       808\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.77      0.74      0.75      2162\n",
      "weighted avg       0.77      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1368\n",
      "        Over       0.73      0.61      0.67       793\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.78      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.87      0.82      1366\n",
      "        Over       0.72      0.57      0.64       795\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.75      0.72      0.73      2161\n",
      "weighted avg       0.76      0.76      0.75      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.89      0.84      1390\n",
      "        Over       0.75      0.61      0.67       771\n",
      "\n",
      "    accuracy                           0.79      2161\n",
      "   macro avg       0.78      0.75      0.76      2161\n",
      "weighted avg       0.78      0.79      0.78      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.88      0.84      1373\n",
      "        Over       0.75      0.62      0.68       788\n",
      "\n",
      "    accuracy                           0.79      2161\n",
      "   macro avg       0.78      0.75      0.76      2161\n",
      "weighted avg       0.78      0.79      0.78      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1376\n",
      "        Over       0.73      0.60      0.66       785\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.74      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1361\n",
      "        Over       0.74      0.60      0.66       800\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.87      0.83      1344\n",
      "        Over       0.75      0.60      0.67       817\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "Avg precision (weighted): 0.7722794030453511\n",
      "Avg recall (weighted): 0.7758756588604396\n",
      "Accuracy: 0.7758756588604396\n"
     ]
    }
   ],
   "source": [
    "# change DataFrame to numpy array\n",
    "XX = X.to_numpy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 30)\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) \n",
    "\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(XX):\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"weighted avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"weighted avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Avg precision (weighted):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Avg recall (weighted):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Accuracy:\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "\n",
    "# We start with k=3 and will increase it to 10.\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into 10 folds \n",
    "\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "print (kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.75\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.76\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Apply k-cross\n",
    "nbclf = GaussianNB()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # for each iteration, get training data and test data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # train the model using training data\n",
    "    nbclf.fit(X_train, y_train)\n",
    "    \n",
    "    # show how model performs with training data and test data\n",
    "    print('Accuracy of GaussianNB classifier on training set: {:.2f}'\n",
    "         .format(nbclf.score(X_train, y_train)))\n",
    "\n",
    "    print('Accuracy of GaussianNB classifier on test set: {:.2f}'\n",
    "         .format(nbclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.76      0.91      0.83      4568\n",
      "        Over       0.77      0.49      0.60      2637\n",
      "\n",
      "    accuracy                           0.76      7205\n",
      "   macro avg       0.76      0.70      0.72      7205\n",
      "weighted avg       0.76      0.76      0.75      7205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.75      0.93      0.83      4561\n",
      "        Over       0.79      0.45      0.57      2643\n",
      "\n",
      "    accuracy                           0.75      7204\n",
      "   macro avg       0.77      0.69      0.70      7204\n",
      "weighted avg       0.76      0.75      0.73      7204\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.74      0.93      0.82      4565\n",
      "        Over       0.78      0.44      0.57      2639\n",
      "\n",
      "    accuracy                           0.75      7204\n",
      "   macro avg       0.76      0.69      0.70      7204\n",
      "weighted avg       0.76      0.75      0.73      7204\n",
      "\n",
      "Avg precision: 6.6361022190369985\n",
      "Avg recall: 6.619922516898608\n",
      "Accuracy: 6.619922516898608\n"
     ]
    }
   ],
   "source": [
    "# Model performance using k-cross\n",
    "nbclf2 = GaussianNB()\n",
    "\n",
    "# !!!!! Please make a summary of the model performance (averaging k folds' results) using result_metrics_dict \n",
    "for train_index, test_index in kf.split(X):\n",
    "    # for each iteration, get training data and test data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # train the model using training data\n",
    "    nbclf2.fit(X_train, y_train)\n",
    "    \n",
    "    # predict y values using test data\n",
    "    y_pred = nbclf2.predict(X_test)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    #print(confusion_mat)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    # Since we can retrieve a dictionary of metrics and access the values using dictionary,\n",
    "    # now we can sum of the results of each iteration and get the average\n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    #print(result_metrics_dict)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"weighted avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"weighted avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Avg precision:\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Avg recall:\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Accuracy:\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8214880376880951\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "y_score = nbclf2.predict_proba(X_test)\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_score[:,1])\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print('Accuracy = ', roc_auc)\n",
    "\n",
    "# Plotting\n",
    "plt.title('ROC')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=('Accuracy = %0.2f'%roc_auc))\n",
    "plt.legend(loc='lower right', prop={'size':8})\n",
    "plt.plot([0,1],[0,1], color='lightgrey', linestyle='--')\n",
    "plt.xlim([-0.05,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
