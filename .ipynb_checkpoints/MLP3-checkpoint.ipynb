{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and training-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "0           0  7129300520  20141013T000000  221900.0         3       1.00   \n",
      "1           1  6414100192  20141209T000000  538000.0         3       2.25   \n",
      "2           2  5631500400  20150225T000000  180000.0         2       1.00   \n",
      "3           3  2487200875  20141209T000000  604000.0         4       3.00   \n",
      "4           4  1954400510  20150218T000000  510000.0         3       2.00   \n",
      "\n",
      "   sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "0         1180      5650     1.0           0  ...      1955             0   \n",
      "1         2570      7242     2.0           0  ...      1951          1991   \n",
      "2          770     10000     1.0           0  ...      1933             0   \n",
      "3         1960      5000     1.0           0  ...      1965             0   \n",
      "4         1680      8080     1.0           0  ...      1987             0   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "0    98178  47.5112 -122.257           1340        5650  2014-10-13   \n",
      "1    98125  47.7210 -122.319           1690        7639  2014-12-09   \n",
      "2    98028  47.7379 -122.233           2720        8062  2015-02-25   \n",
      "3    98136  47.5208 -122.393           1360        5000  2014-12-09   \n",
      "4    98074  47.6168 -122.045           1800        7503  2015-02-18   \n",
      "\n",
      "   most_recent  price_range  \n",
      "0         1955            0  \n",
      "1         1991            0  \n",
      "2         1933            0  \n",
      "3         1965            1  \n",
      "4         1987            0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "       Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "21608       21608   263000018  20140521T000000  360000.0         3       2.50   \n",
      "21609       21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
      "21610       21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
      "21611       21611   291310100  20150116T000000  400000.0         3       2.50   \n",
      "21612       21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
      "\n",
      "       sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "21608         1530      1131     3.0           0  ...      2009             0   \n",
      "21609         2310      5813     2.0           0  ...      2014             0   \n",
      "21610         1020      1350     2.0           0  ...      2009             0   \n",
      "21611         1600      2388     2.0           0  ...      2004             0   \n",
      "21612         1020      1076     2.0           0  ...      2008             0   \n",
      "\n",
      "       zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "21608    98103  47.6993 -122.346           1530        1509  2014-05-21   \n",
      "21609    98146  47.5107 -122.362           1830        7200  2015-02-23   \n",
      "21610    98144  47.5944 -122.299           1020        2007  2014-06-23   \n",
      "21611    98027  47.5345 -122.069           1410        1287  2015-01-16   \n",
      "21612    98144  47.5941 -122.299           1020        1357  2014-10-15   \n",
      "\n",
      "       most_recent  price_range  \n",
      "21608         2009            0  \n",
      "21609         2014            0  \n",
      "21610         2009            0  \n",
      "21611         2004            0  \n",
      "21612         2008            0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read data from CSV file to dataframe\n",
    "df = pd.read_csv(r\"./input/kc_sales_cleaned.csv\")\n",
    "\n",
    "# make sure you understand the type of the object\n",
    "print(type(df))\n",
    "\n",
    "# check the top five and the botoom five data tuples\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Under', 'Over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.83      0.83      1360\n",
      "        Over       0.71      0.69      0.70       802\n",
      "\n",
      "    accuracy                           0.78      2162\n",
      "   macro avg       0.76      0.76      0.76      2162\n",
      "weighted avg       0.78      0.78      0.78      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.84      0.82      1355\n",
      "        Over       0.70      0.66      0.68       807\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.75      0.75      2162\n",
      "weighted avg       0.77      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.82      1348\n",
      "        Over       0.70      0.66      0.68       814\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.75      0.75      2162\n",
      "weighted avg       0.76      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.82      1367\n",
      "        Over       0.69      0.65      0.67       794\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.74      0.74      2161\n",
      "weighted avg       0.76      0.77      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1408\n",
      "        Over       0.66      0.66      0.66       753\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.74      0.74      0.74      2161\n",
      "weighted avg       0.76      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.84      0.83      1370\n",
      "        Over       0.70      0.67      0.69       791\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.76      0.76      2161\n",
      "weighted avg       0.78      0.78      0.78      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.81      0.82      1394\n",
      "        Over       0.67      0.69      0.68       767\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.81      1355\n",
      "        Over       0.69      0.66      0.68       806\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.75      0.74      0.75      2161\n",
      "weighted avg       0.76      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.83      0.81      1349\n",
      "        Over       0.69      0.64      0.67       812\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.74      0.73      0.74      2161\n",
      "weighted avg       0.75      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1388\n",
      "        Over       0.68      0.68      0.68       773\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "Average precision (ENTROPY): 0.7506297917950204\n",
      "Average recall (ENTROPY): 0.7466249810985011\n",
      "Average accuracy (ENTROPY): 0.768194543674533\n"
     ]
    }
   ],
   "source": [
    "# Entropy\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "# decision tree classifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='entropy', random_state=42)\n",
    "\n",
    "# k-fold cross validation (k=10)\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 2 folds\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "\n",
    "# each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"macro avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"macro avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Average precision (ENTROPY):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Average recall (ENTROPY):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Average accuracy (ENTROPY):\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.86      0.84      1368\n",
      "        Over       0.74      0.66      0.70       794\n",
      "\n",
      "    accuracy                           0.79      2162\n",
      "   macro avg       0.78      0.76      0.77      2162\n",
      "weighted avg       0.79      0.79      0.79      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.84      0.82      1378\n",
      "        Over       0.70      0.63      0.66       784\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.74      0.74      2162\n",
      "weighted avg       0.76      0.77      0.76      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.81      0.80      1339\n",
      "        Over       0.68      0.64      0.66       823\n",
      "\n",
      "    accuracy                           0.75      2162\n",
      "   macro avg       0.73      0.73      0.73      2162\n",
      "weighted avg       0.75      0.75      0.75      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.81      0.83      0.82      1361\n",
      "        Over       0.70      0.68      0.69       800\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.75      0.76      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1372\n",
      "        Over       0.69      0.68      0.68       789\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.85      0.82      1370\n",
      "        Over       0.70      0.63      0.66       791\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.74      0.74      2161\n",
      "weighted avg       0.76      0.77      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.81      0.81      1411\n",
      "        Over       0.64      0.66      0.65       750\n",
      "\n",
      "    accuracy                           0.75      2161\n",
      "   macro avg       0.73      0.73      0.73      2161\n",
      "weighted avg       0.76      0.75      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1348\n",
      "        Over       0.73      0.61      0.67       813\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.86      0.83      1381\n",
      "        Over       0.71      0.62      0.66       780\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.86      0.83      1366\n",
      "        Over       0.73      0.63      0.67       795\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.78      0.77      2161\n",
      "\n",
      "Average precision (GINI): 0.7527015625819437\n",
      "Average recall (GINI): 0.7428066335756423\n",
      "Average accuracy (GINI): 0.7688892446665105\n"
     ]
    }
   ],
   "source": [
    "# Gini\n",
    "\n",
    "# Construct a decision tree using gini index\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='gini', random_state=42)\n",
    "\n",
    "# 10-fold CV\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) \n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"macro avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"macro avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Average precision (GINI):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Average recall (GINI):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Average accuracy (GINI):\", accuracy_sum/kf.get_n_splits(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance information for gini classifier on max depth =  3 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.83      0.84      0.83      2726\n",
      "        Over       0.72      0.70      0.71      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.77      0.77      0.77      4323\n",
      "weighted avg       0.79      0.79      0.79      4323\n",
      "\n",
      "Precision (GINI): 0.7715737156931738\n",
      "Recall (GINI): 0.7694788145968849\n",
      "Accuracy (GINI): 0.7869535045107564\n",
      "\n",
      "Performance information for entropy classifier on max depth =  3 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.84      0.81      0.83      2726\n",
      "        Over       0.69      0.74      0.72      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.78      0.77      4323\n",
      "weighted avg       0.79      0.78      0.79      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7688380414160795\n",
      "Recall (ENTROPY): 0.7757599653789593\n",
      "Accuracy (ENTROPY): 0.7844089752486699\n",
      "\n",
      "Performance information for gini classifier on max depth =  4 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.90      0.84      2726\n",
      "        Over       0.78      0.59      0.67      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (GINI): 0.784653704893585\n",
      "Recall (GINI): 0.7472834014253615\n",
      "Accuracy (GINI): 0.7874161461947722\n",
      "\n",
      "Performance information for entropy classifier on max depth =  4 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.90      0.84      2726\n",
      "        Over       0.78      0.60      0.68      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.79      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7861806827314528\n",
      "Recall (ENTROPY): 0.7494750106927378\n",
      "Accuracy (ENTROPY): 0.7890353920888272\n",
      "\n",
      "Performance information for gini classifier on max depth =  5 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.88      0.84      2726\n",
      "        Over       0.76      0.63      0.69      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (GINI): 0.7792928075916197\n",
      "Recall (GINI): 0.754522649079276\n",
      "Accuracy (GINI): 0.7878787878787878\n",
      "\n",
      "Performance information for entropy classifier on max depth =  5 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.87      0.84      2726\n",
      "        Over       0.74      0.67      0.70      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.77      0.77      4323\n",
      "weighted avg       0.79      0.79      0.79      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7800784522996014\n",
      "Recall (ENTROPY): 0.7664360358357173\n",
      "Accuracy (ENTROPY): 0.7922738838769373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Change max depth and observe results \n",
    "\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)\n",
    "\n",
    "for i in [3,4,5]:\n",
    "    tree_clf_gini = DecisionTreeClassifier(max_depth= i, criterion=\"gini\", random_state=42)\n",
    "    tree_clf_entropy = DecisionTreeClassifier(max_depth = i, criterion=\"entropy\", random_state=42)\n",
    "    \n",
    "    tree_clf_gini.fit(X_train, y_train)\n",
    "    tree_clf_entropy.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_gini = tree_clf_gini.predict(X_test)\n",
    "    \n",
    "    y_pred_entropy = tree_clf_entropy.predict(X_test)    \n",
    "    \n",
    "    print(\"Performance information for gini classifier on max depth = \", i, \":\")\n",
    "    print()\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_gini, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict_gini = classification_report(y_test, y_pred_gini, target_names=target_names, output_dict=True)\n",
    "    print(\"Precision (GINI):\", result_metrics_dict_gini[\"macro avg\"][\"precision\"])\n",
    "    print(\"Recall (GINI):\", result_metrics_dict_gini[\"macro avg\"][\"recall\"])\n",
    "    print(\"Accuracy (GINI):\", result_metrics_dict_gini[\"accuracy\"])\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance information for entropy classifier on max depth = \", i, \":\")\n",
    "    print()\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_entropy, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict_entropy = classification_report(y_test, y_pred_entropy, target_names=target_names, output_dict=True)\n",
    "    print(\"Precision (ENTROPY):\", result_metrics_dict_entropy[\"macro avg\"][\"precision\"])\n",
    "    print(\"Recall (ENTROPY):\", result_metrics_dict_entropy[\"macro avg\"][\"recall\"])\n",
    "    print(\"Accuracy (ENTROPY):\", result_metrics_dict_entropy[\"accuracy\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for K =  3 \n",
      "\n",
      "Average precision (GINI): 0.7842357101370668\n",
      "Average recall (GINI): 0.7543143091297481\n",
      "Average accuracy (GINI): 0.7910518779052375 \n",
      "\n",
      "Average precision (ENTROPY): 0.7784626818032855\n",
      "Average recall (ENTROPY): 0.7620881182030738\n",
      "Average accuracy (ENTROPY): 0.7905891077809986 \n",
      "\n",
      "Results for K =  5 \n",
      "\n",
      "Average precision (GINI): 0.7813917596216193\n",
      "Average recall (GINI): 0.7533246051759319\n",
      "Average accuracy (GINI): 0.7894326195356607 \n",
      "\n",
      "Average precision (ENTROPY): 0.7783766143806481\n",
      "Average recall (ENTROPY): 0.7572549110496708\n",
      "Average accuracy (ENTROPY): 0.7886458717686132 \n",
      "\n",
      "Results for K =  7 \n",
      "\n",
      "Average precision (GINI): 0.7791384270824023\n",
      "Average recall (GINI): 0.7519252266027997\n",
      "Average accuracy (GINI): 0.7874887874151459 \n",
      "\n",
      "Average precision (ENTROPY): 0.7776391119890638\n",
      "Average recall (ENTROPY): 0.7586305424816775\n",
      "Average accuracy (ENTROPY): 0.7888305360916352 \n",
      "\n",
      "Results for K =  10 \n",
      "\n",
      "Average precision (GINI): 0.7787629914134627\n",
      "Average recall (GINI): 0.7540267001654275\n",
      "Average accuracy (GINI): 0.7880897424317468 \n",
      "\n",
      "Average precision (ENTROPY): 0.777115373088708\n",
      "Average recall (ENTROPY): 0.7562798880279982\n",
      "Average accuracy (ENTROPY): 0.7874883403159447 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change k value and observe results\n",
    "\n",
    "for k in [3,5,7,10]:\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    precision_sum_gini = recall_sum_gini = accuracy_sum_gini = 0\n",
    "    precision_sum_entropy = recall_sum_entropy = accuracy_sum_entropy = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        tree_clf_gini = DecisionTreeClassifier(max_depth= i, criterion=\"gini\", random_state=42)\n",
    "        tree_clf_entropy = DecisionTreeClassifier(max_depth = i, criterion=\"entropy\", random_state=42)\n",
    "    \n",
    "        tree_clf_gini.fit(X_train, y_train)\n",
    "        tree_clf_entropy.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred_gini = tree_clf_gini.predict(X_test)\n",
    "        y_pred_entropy = tree_clf_entropy.predict(X_test)  \n",
    "        \n",
    "    \n",
    "        result_metrics_dict_gini = classification_report(y_test, y_pred_gini, target_names=target_names, output_dict=True)\n",
    "        result_metrics_dict_entropy = classification_report(y_test, y_pred_entropy, target_names=target_names, output_dict=True)\n",
    "    \n",
    "        precision_sum_gini += result_metrics_dict_gini[\"macro avg\"][\"precision\"]\n",
    "        recall_sum_gini += result_metrics_dict_gini[\"macro avg\"][\"recall\"]\n",
    "        accuracy_sum_gini += result_metrics_dict_gini[\"accuracy\"]\n",
    "        \n",
    "        precision_sum_entropy += result_metrics_dict_entropy[\"macro avg\"][\"precision\"]\n",
    "        recall_sum_entropy += result_metrics_dict_entropy[\"macro avg\"][\"recall\"]\n",
    "        accuracy_sum_entropy += result_metrics_dict_entropy[\"accuracy\"]\n",
    "        \n",
    "    print(\"Results for K = \", k, \"\\n\")\n",
    "    \n",
    "    print(\"Average precision (GINI):\", precision_sum_gini/kf.get_n_splits(X))\n",
    "    print(\"Average recall (GINI):\", recall_sum_gini/kf.get_n_splits(X))\n",
    "    print(\"Average accuracy (GINI):\", accuracy_sum_gini/kf.get_n_splits(X), \"\\n\")\n",
    "    \n",
    "    print(\"Average precision (ENTROPY):\", precision_sum_entropy/kf.get_n_splits(X))\n",
    "    print(\"Average recall (ENTROPY):\", recall_sum_entropy/kf.get_n_splits(X))\n",
    "    print(\"Average accuracy (ENTROPY):\", accuracy_sum_entropy/kf.get_n_splits(X), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The performance of the gini and entropy classifiers was actually fairly similar on the same testing set, and the best performing depth appeared to be max depth = 3. Changing the value of K didn't change the results significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot important features\n",
    "def plot_feature_importances(clf, feature_names):\n",
    "    c_features = len(feature_names)\n",
    "    plt.barh(range(c_features), clf.feature_importances_)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature name\")\n",
    "    plt.yticks(np.arange(c_features), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DT classifier on training set: 1.00\n",
      "Accuracy of DT classifier on test set: 0.74\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Find the important features of the entropy DT model\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf1.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf1.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=60)\n",
    "\n",
    "# call the function above\n",
    "plot_feature_importances(clf1, X.columns.values.tolist())\n",
    "plt.show()\n",
    "\n",
    "print('Feature importances: {}'.format(tree_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will consider entropy Decision Tree with max depth = 3 and K = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1\n",
      "[[2179  547]\n",
      " [ 634  963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.77      0.80      0.79      2726\n",
      "        Over       0.64      0.60      0.62      1597\n",
      "\n",
      "    accuracy                           0.73      4323\n",
      "   macro avg       0.71      0.70      0.70      4323\n",
      "weighted avg       0.72      0.73      0.73      4323\n",
      "\n",
      "k=5\n",
      "[[2355  371]\n",
      " [ 617  980]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.86      0.83      2726\n",
      "        Over       0.73      0.61      0.66      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.76      0.74      0.75      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=15\n",
      "[[2364  362]\n",
      " [ 615  982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      2726\n",
      "        Over       0.73      0.61      0.67      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.76      0.74      0.75      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=20\n",
      "[[2422  304]\n",
      " [ 675  922]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.89      0.83      2726\n",
      "        Over       0.75      0.58      0.65      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.77      0.73      0.74      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=25\n",
      "[[2389  337]\n",
      " [ 619  978]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.88      0.83      2726\n",
      "        Over       0.74      0.61      0.67      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.74      0.75      4323\n",
      "weighted avg       0.78      0.78      0.77      4323\n",
      "\n",
      "k=30\n",
      "[[2417  309]\n",
      " [ 658  939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.89      0.83      2726\n",
      "        Over       0.75      0.59      0.66      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.74      0.75      4323\n",
      "weighted avg       0.77      0.78      0.77      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the best k value\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_value = [1, 5, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_value:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(f\"k={k}\")\n",
    "    \n",
    "    # plot a confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_mat)\n",
    "    \n",
    "    # Print classification report\n",
    "    target_names = ['Under', 'Over']\n",
    "   \n",
    "    #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    result_metrics = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    print(result_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Performance with k = 1 *******\n",
      "Precision:  0.7242837884223011\n",
      "Recall:  0.7250729572577909\n",
      "Accuracy:  0.7250729572577909\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 5 *******\n",
      "Precision:  0.7645500570315034\n",
      "Recall:  0.7681027696464412\n",
      "Accuracy:  0.7681027696464412\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 10 *******\n",
      "Precision:  0.7664802628152053\n",
      "Recall:  0.769444475484165\n",
      "Accuracy:  0.769444475484165\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 15 *******\n",
      "Precision:  0.7711758577175605\n",
      "Recall:  0.7749503225326665\n",
      "Accuracy:  0.7749503225326665\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 20 *******\n",
      "Precision:  0.7671374572824109\n",
      "Recall:  0.7707399749515877\n",
      "Accuracy:  0.7707399749515877\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 25 *******\n",
      "Precision:  0.7724776674099404\n",
      "Recall:  0.776014212167579\n",
      "Accuracy:  0.776014212167579\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 30 *******\n",
      "Precision:  0.7694424662546062\n",
      "Recall:  0.7730529842893202\n",
      "Accuracy:  0.7730529842893202\n",
      "**************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-Cross validation (k=3) on the original data\n",
    "# KNN classifier with varying k values\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into k folds \n",
    "\n",
    "k_values = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_values:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "        \n",
    "        #print(f\"k={k}\")\n",
    "        #print(\"training score: \", knn.score(X_train, y_train))\n",
    "        #print(\"testing score: \", knn.score(X_test, y_test))\n",
    "    \n",
    "        # plot a confusion matrix\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "        #print(confusion_mat)\n",
    "    \n",
    "        #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        results = classification_report(y_test, y_pred, target_names=target_names)\n",
    "        #print(results)\n",
    "\n",
    "        metrics_dict = classification_report(y_test, y_pred, \n",
    "                        target_names=target_names, output_dict=True)\n",
    "\n",
    "        avg_precision = metrics_dict['weighted avg']['precision']\n",
    "        #print('precision (weighted):', avg_precision)\n",
    "        precision.append(avg_precision)\n",
    "    \n",
    "        avg_recall = metrics_dict['weighted avg']['recall']\n",
    "        #print('recall avg (weighted):', avg_recall)\n",
    "        recall.append(avg_recall)\n",
    "    \n",
    "        avg_accuracy = metrics_dict['accuracy']\n",
    "        #print('accuracy: ', avg_accuracy)\n",
    "        accuracy.append(avg_accuracy)\n",
    "        \n",
    "    print('\\n******* Performance with k =', k, '*******')\n",
    "    print('Precision: ', sum(precision)/len(precision))\n",
    "    print('Recall: ', sum(recall)/len(recall))\n",
    "    print('Accuracy: ', sum(accuracy)/len(accuracy))\n",
    "    print('**************************************\\n')\n",
    "    \n",
    "    plt.plot(k, np.mean(test_score), 'bo')\n",
    "    plt.plot(k, np.mean(train_score), 'rx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Cross validation (k=3) on the original data\n",
    "# KNN classifier with varying training size\n",
    "t = [x/10 for x in range(1, 9)]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        knn.fit(X_train, y_train)\n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "    \n",
    "    plt.plot(s, np.mean(train_score), 'rx')\n",
    "    plt.plot(s, np.mean(test_score), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg precision (weighted): 0.7665288961960375\n",
      "Avg recall (weighted): 0.7704620881066537\n",
      "Accuracy: 0.7704620881066537\n"
     ]
    }
   ],
   "source": [
    "# change DataFrame to numpy array\n",
    "XX = X.to_numpy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 30)\n",
    "\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(XX):\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"weighted avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"weighted avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Avg precision (weighted):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Avg recall (weighted):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Accuracy:\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "\n",
    "# We start with k=3 and will increase it to 10.\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into 10 folds \n",
    "\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "print (kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB classifier on training set: 0.75\n",
      "Accuracy of GaussianNB classifier on test set: 0.77\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.75\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Apply k-cross\n",
    "nbclf = GaussianNB()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # for each iteration, get training data and test data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # train the model using training data\n",
    "    nbclf.fit(X_train, y_train)\n",
    "    \n",
    "    # show how model performs with training data and test data\n",
    "    print('Accuracy of GaussianNB classifier on training set: {:.2f}'\n",
    "         .format(nbclf.score(X_train, y_train)))\n",
    "\n",
    "    print('Accuracy of GaussianNB classifier on test set: {:.2f}'\n",
    "         .format(nbclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4223  316]\n",
      " [1419 1247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.75      0.93      0.83      4539\n",
      "        Over       0.80      0.47      0.59      2666\n",
      "\n",
      "    accuracy                           0.76      7205\n",
      "   macro avg       0.77      0.70      0.71      7205\n",
      "weighted avg       0.77      0.76      0.74      7205\n",
      "\n",
      "{'Under': {'precision': 0.7484934420418291, 'recall': 0.9303811412205332, 'f1-score': 0.8295845201846577, 'support': 4539}, 'Over': {'precision': 0.7978246960972489, 'recall': 0.46774193548387094, 'f1-score': 0.5897375266020336, 'support': 2666}, 'accuracy': 0.7591950034698126, 'macro avg': {'precision': 0.773159069069539, 'recall': 0.6990615383522021, 'f1-score': 0.7096610233933456, 'support': 7205}, 'weighted avg': {'precision': 0.7667470330635846, 'recall': 0.7591950034698126, 'f1-score': 0.740836139214321, 'support': 7205}}\n",
      "[[4239  344]\n",
      " [1448 1173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.75      0.92      0.83      4583\n",
      "        Over       0.77      0.45      0.57      2621\n",
      "\n",
      "    accuracy                           0.75      7204\n",
      "   macro avg       0.76      0.69      0.70      7204\n",
      "weighted avg       0.76      0.75      0.73      7204\n",
      "\n",
      "{'Under': {'precision': 0.7453842096008441, 'recall': 0.9249399956360462, 'f1-score': 0.8255111976630963, 'support': 4583}, 'Over': {'precision': 0.7732366512854317, 'recall': 0.44753910721098816, 'f1-score': 0.5669405509908169, 'support': 2621}, 'accuracy': 0.7512493059411438, 'macro avg': {'precision': 0.759310430443138, 'recall': 0.6862395514235172, 'f1-score': 0.6962258743269566, 'support': 7204}, 'weighted avg': {'precision': 0.755517642368099, 'recall': 0.7512493059411438, 'f1-score': 0.7314365634421018, 'support': 7204}}\n",
      "[[4207  365]\n",
      " [1380 1252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.75      0.92      0.83      4572\n",
      "        Over       0.77      0.48      0.59      2632\n",
      "\n",
      "    accuracy                           0.76      7204\n",
      "   macro avg       0.76      0.70      0.71      7204\n",
      "weighted avg       0.76      0.76      0.74      7204\n",
      "\n",
      "{'Under': {'precision': 0.7529980311437265, 'recall': 0.9201662292213474, 'f1-score': 0.8282311251107393, 'support': 4572}, 'Over': {'precision': 0.7742733457019171, 'recall': 0.4756838905775076, 'f1-score': 0.5893151329724641, 'support': 2632}, 'accuracy': 0.7577734591893392, 'macro avg': {'precision': 0.7636356884228218, 'recall': 0.6979250598994275, 'f1-score': 0.7087731290416017, 'support': 7204}, 'weighted avg': {'precision': 0.7607710222482736, 'recall': 0.7577734591893392, 'f1-score': 0.7409425505260724, 'support': 7204}}\n"
     ]
    }
   ],
   "source": [
    "# Model performance using k-cross\n",
    "nbclf2 = GaussianNB()\n",
    "\n",
    "# !!!!! Please make a summary of the model performance (averaging k folds' results) using result_metrics_dict \n",
    "for train_index, test_index in kf.split(X):\n",
    "    # for each iteration, get training data and test data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # train the model using training data\n",
    "    nbclf2.fit(X_train, y_train)\n",
    "    \n",
    "    # predict y values using test data\n",
    "    y_pred = nbclf2.predict(X_test)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_mat)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    # Since we can retrieve a dictionary of metrics and access the values using dictionary,\n",
    "    # now we can sum of the results of each iteration and get the average\n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    print(result_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8214880376880951\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "y_score = nbclf2.predict_proba(X_test)\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_score[:,1])\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print('Accuracy = ', roc_auc)\n",
    "\n",
    "# Plotting\n",
    "plt.title('ROC')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=('Accuracy = %0.2f'%roc_auc))\n",
    "plt.legend(loc='lower right', prop={'size':8})\n",
    "plt.plot([0,1],[0,1], color='lightgrey', linestyle='--')\n",
    "plt.xlim([-0.05,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
