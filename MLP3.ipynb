{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and training-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "0           0  7129300520  20141013T000000  221900.0         3       1.00   \n",
      "1           1  6414100192  20141209T000000  538000.0         3       2.25   \n",
      "2           2  5631500400  20150225T000000  180000.0         2       1.00   \n",
      "3           3  2487200875  20141209T000000  604000.0         4       3.00   \n",
      "4           4  1954400510  20150218T000000  510000.0         3       2.00   \n",
      "\n",
      "   sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "0         1180      5650     1.0           0  ...      1955             0   \n",
      "1         2570      7242     2.0           0  ...      1951          1991   \n",
      "2          770     10000     1.0           0  ...      1933             0   \n",
      "3         1960      5000     1.0           0  ...      1965             0   \n",
      "4         1680      8080     1.0           0  ...      1987             0   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "0    98178  47.5112 -122.257           1340        5650  2014-10-13   \n",
      "1    98125  47.7210 -122.319           1690        7639  2014-12-09   \n",
      "2    98028  47.7379 -122.233           2720        8062  2015-02-25   \n",
      "3    98136  47.5208 -122.393           1360        5000  2014-12-09   \n",
      "4    98074  47.6168 -122.045           1800        7503  2015-02-18   \n",
      "\n",
      "   most_recent  price_range  \n",
      "0         1955            0  \n",
      "1         1991            0  \n",
      "2         1933            0  \n",
      "3         1965            1  \n",
      "4         1987            0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "       Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "21608       21608   263000018  20140521T000000  360000.0         3       2.50   \n",
      "21609       21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
      "21610       21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
      "21611       21611   291310100  20150116T000000  400000.0         3       2.50   \n",
      "21612       21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
      "\n",
      "       sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "21608         1530      1131     3.0           0  ...      2009             0   \n",
      "21609         2310      5813     2.0           0  ...      2014             0   \n",
      "21610         1020      1350     2.0           0  ...      2009             0   \n",
      "21611         1600      2388     2.0           0  ...      2004             0   \n",
      "21612         1020      1076     2.0           0  ...      2008             0   \n",
      "\n",
      "       zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "21608    98103  47.6993 -122.346           1530        1509  2014-05-21   \n",
      "21609    98146  47.5107 -122.362           1830        7200  2015-02-23   \n",
      "21610    98144  47.5944 -122.299           1020        2007  2014-06-23   \n",
      "21611    98027  47.5345 -122.069           1410        1287  2015-01-16   \n",
      "21612    98144  47.5941 -122.299           1020        1357  2014-10-15   \n",
      "\n",
      "       most_recent  price_range  \n",
      "21608         2009            0  \n",
      "21609         2014            0  \n",
      "21610         2009            0  \n",
      "21611         2004            0  \n",
      "21612         2008            0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read data from CSV file to dataframe\n",
    "df = pd.read_csv(r\"./input/kc_sales_cleaned.csv\")\n",
    "\n",
    "# make sure you understand the type of the object\n",
    "print(type(df))\n",
    "\n",
    "# check the top five and the botoom five data tuples\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Under', 'Over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.83      0.83      1360\n",
      "        Over       0.71      0.69      0.70       802\n",
      "\n",
      "    accuracy                           0.78      2162\n",
      "   macro avg       0.76      0.76      0.76      2162\n",
      "weighted avg       0.78      0.78      0.78      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.84      0.82      1355\n",
      "        Over       0.70      0.66      0.68       807\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.75      0.75      2162\n",
      "weighted avg       0.77      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.82      1348\n",
      "        Over       0.70      0.66      0.68       814\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.75      0.75      2162\n",
      "weighted avg       0.76      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.82      1367\n",
      "        Over       0.69      0.65      0.67       794\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.74      0.74      2161\n",
      "weighted avg       0.76      0.77      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1408\n",
      "        Over       0.66      0.66      0.66       753\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.74      0.74      0.74      2161\n",
      "weighted avg       0.76      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.84      0.83      1370\n",
      "        Over       0.70      0.67      0.69       791\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.76      0.76      2161\n",
      "weighted avg       0.78      0.78      0.78      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.81      0.82      1394\n",
      "        Over       0.67      0.69      0.68       767\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.83      0.81      1355\n",
      "        Over       0.69      0.66      0.68       806\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.75      0.74      0.75      2161\n",
      "weighted avg       0.76      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.83      0.81      1349\n",
      "        Over       0.69      0.64      0.67       812\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.74      0.73      0.74      2161\n",
      "weighted avg       0.75      0.76      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1388\n",
      "        Over       0.68      0.68      0.68       773\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "Average precision (ENTROPY): 0.7506297917950204\n",
      "Average recall (ENTROPY): 0.7466249810985011\n",
      "Average accuracy (ENTROPY): 0.768194543674533\n"
     ]
    }
   ],
   "source": [
    "# Entropy\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "# decision tree classifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='entropy', random_state=42)\n",
    "\n",
    "# k-fold cross validation (k=10)\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 2 folds\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "\n",
    "# each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"macro avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"macro avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Average precision (ENTROPY):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Average recall (ENTROPY):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Average accuracy (ENTROPY):\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.86      0.84      1368\n",
      "        Over       0.74      0.66      0.70       794\n",
      "\n",
      "    accuracy                           0.79      2162\n",
      "   macro avg       0.78      0.76      0.77      2162\n",
      "weighted avg       0.79      0.79      0.79      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.84      0.82      1378\n",
      "        Over       0.70      0.63      0.66       784\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.75      0.74      0.74      2162\n",
      "weighted avg       0.76      0.77      0.76      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.81      0.80      1339\n",
      "        Over       0.68      0.64      0.66       823\n",
      "\n",
      "    accuracy                           0.75      2162\n",
      "   macro avg       0.73      0.73      0.73      2162\n",
      "weighted avg       0.75      0.75      0.75      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.81      0.83      0.82      1361\n",
      "        Over       0.70      0.68      0.69       800\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.75      0.76      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.82      0.82      1372\n",
      "        Over       0.69      0.68      0.68       789\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.75      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.85      0.82      1370\n",
      "        Over       0.70      0.63      0.66       791\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.75      0.74      0.74      2161\n",
      "weighted avg       0.76      0.77      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.81      0.81      1411\n",
      "        Over       0.64      0.66      0.65       750\n",
      "\n",
      "    accuracy                           0.75      2161\n",
      "   macro avg       0.73      0.73      0.73      2161\n",
      "weighted avg       0.76      0.75      0.76      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1348\n",
      "        Over       0.73      0.61      0.67       813\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.86      0.83      1381\n",
      "        Over       0.71      0.62      0.66       780\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.86      0.83      1366\n",
      "        Over       0.73      0.63      0.67       795\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.78      0.77      2161\n",
      "\n",
      "Average precision (GINI): 0.7527015625819437\n",
      "Average recall (GINI): 0.7428066335756423\n",
      "Average accuracy (GINI): 0.7688892446665105\n"
     ]
    }
   ],
   "source": [
    "# Gini\n",
    "\n",
    "# Construct a decision tree using gini index\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='gini', random_state=42)\n",
    "\n",
    "# 10-fold CV\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) \n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"macro avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"macro avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Average precision (GINI):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Average recall (GINI):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Average accuracy (GINI):\", accuracy_sum/kf.get_n_splits(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance information for gini classifier on max depth =  3 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.83      0.84      0.83      2726\n",
      "        Over       0.72      0.70      0.71      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.77      0.77      0.77      4323\n",
      "weighted avg       0.79      0.79      0.79      4323\n",
      "\n",
      "Precision (GINI): 0.7715737156931738\n",
      "Recall (GINI): 0.7694788145968849\n",
      "Accuracy (GINI): 0.7869535045107564\n",
      "\n",
      "Performance information for entropy classifier on max depth =  3 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.84      0.81      0.83      2726\n",
      "        Over       0.69      0.74      0.72      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.78      0.77      4323\n",
      "weighted avg       0.79      0.78      0.79      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7688380414160795\n",
      "Recall (ENTROPY): 0.7757599653789593\n",
      "Accuracy (ENTROPY): 0.7844089752486699\n",
      "\n",
      "Performance information for gini classifier on max depth =  4 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.90      0.84      2726\n",
      "        Over       0.78      0.59      0.67      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (GINI): 0.784653704893585\n",
      "Recall (GINI): 0.7472834014253615\n",
      "Accuracy (GINI): 0.7874161461947722\n",
      "\n",
      "Performance information for entropy classifier on max depth =  4 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.90      0.84      2726\n",
      "        Over       0.78      0.60      0.68      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.79      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7861806827314528\n",
      "Recall (ENTROPY): 0.7494750106927378\n",
      "Accuracy (ENTROPY): 0.7890353920888272\n",
      "\n",
      "Performance information for gini classifier on max depth =  5 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.88      0.84      2726\n",
      "        Over       0.76      0.63      0.69      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.75      0.76      4323\n",
      "weighted avg       0.79      0.79      0.78      4323\n",
      "\n",
      "Precision (GINI): 0.7792928075916197\n",
      "Recall (GINI): 0.754522649079276\n",
      "Accuracy (GINI): 0.7878787878787878\n",
      "\n",
      "Performance information for entropy classifier on max depth =  5 :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.82      0.87      0.84      2726\n",
      "        Over       0.74      0.67      0.70      1597\n",
      "\n",
      "    accuracy                           0.79      4323\n",
      "   macro avg       0.78      0.77      0.77      4323\n",
      "weighted avg       0.79      0.79      0.79      4323\n",
      "\n",
      "Precision (ENTROPY): 0.7800784522996014\n",
      "Recall (ENTROPY): 0.7664360358357173\n",
      "Accuracy (ENTROPY): 0.7922738838769373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Change max depth and observe results \n",
    "\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)\n",
    "\n",
    "for i in [3,4,5]:\n",
    "    tree_clf_gini = DecisionTreeClassifier(max_depth= i, criterion=\"gini\", random_state=42)\n",
    "    tree_clf_entropy = DecisionTreeClassifier(max_depth = i, criterion=\"entropy\", random_state=42)\n",
    "    \n",
    "    tree_clf_gini.fit(X_train, y_train)\n",
    "    tree_clf_entropy.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_gini = tree_clf_gini.predict(X_test)\n",
    "    \n",
    "    y_pred_entropy = tree_clf_entropy.predict(X_test)    \n",
    "    \n",
    "    print(\"Performance information for gini classifier on max depth = \", i, \":\")\n",
    "    print()\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_gini, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict_gini = classification_report(y_test, y_pred_gini, target_names=target_names, output_dict=True)\n",
    "    print(\"Precision (GINI):\", result_metrics_dict_gini[\"macro avg\"][\"precision\"])\n",
    "    print(\"Recall (GINI):\", result_metrics_dict_gini[\"macro avg\"][\"recall\"])\n",
    "    print(\"Accuracy (GINI):\", result_metrics_dict_gini[\"accuracy\"])\n",
    "    print()\n",
    "    \n",
    "    print(\"Performance information for entropy classifier on max depth = \", i, \":\")\n",
    "    print()\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_entropy, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict_entropy = classification_report(y_test, y_pred_entropy, target_names=target_names, output_dict=True)\n",
    "    print(\"Precision (ENTROPY):\", result_metrics_dict_entropy[\"macro avg\"][\"precision\"])\n",
    "    print(\"Recall (ENTROPY):\", result_metrics_dict_entropy[\"macro avg\"][\"recall\"])\n",
    "    print(\"Accuracy (ENTROPY):\", result_metrics_dict_entropy[\"accuracy\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for K =  3 \n",
      "\n",
      "Average precision (GINI): 0.7842357101370668\n",
      "Average recall (GINI): 0.7543143091297481\n",
      "Average accuracy (GINI): 0.7910518779052375 \n",
      "\n",
      "Average precision (ENTROPY): 0.7784626818032855\n",
      "Average recall (ENTROPY): 0.7620881182030738\n",
      "Average accuracy (ENTROPY): 0.7905891077809986 \n",
      "\n",
      "Results for K =  5 \n",
      "\n",
      "Average precision (GINI): 0.7813917596216193\n",
      "Average recall (GINI): 0.7533246051759319\n",
      "Average accuracy (GINI): 0.7894326195356607 \n",
      "\n",
      "Average precision (ENTROPY): 0.7783766143806481\n",
      "Average recall (ENTROPY): 0.7572549110496708\n",
      "Average accuracy (ENTROPY): 0.7886458717686132 \n",
      "\n",
      "Results for K =  7 \n",
      "\n",
      "Average precision (GINI): 0.7791384270824023\n",
      "Average recall (GINI): 0.7519252266027997\n",
      "Average accuracy (GINI): 0.7874887874151459 \n",
      "\n",
      "Average precision (ENTROPY): 0.7776391119890638\n",
      "Average recall (ENTROPY): 0.7586305424816775\n",
      "Average accuracy (ENTROPY): 0.7888305360916352 \n",
      "\n",
      "Results for K =  10 \n",
      "\n",
      "Average precision (GINI): 0.7787629914134627\n",
      "Average recall (GINI): 0.7540267001654275\n",
      "Average accuracy (GINI): 0.7880897424317468 \n",
      "\n",
      "Average precision (ENTROPY): 0.777115373088708\n",
      "Average recall (ENTROPY): 0.7562798880279982\n",
      "Average accuracy (ENTROPY): 0.7874883403159447 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change k value and observe results\n",
    "\n",
    "for k in [3,5,7,10]:\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    precision_sum_gini = recall_sum_gini = accuracy_sum_gini = 0\n",
    "    precision_sum_entropy = recall_sum_entropy = accuracy_sum_entropy = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        tree_clf_gini = DecisionTreeClassifier(max_depth= i, criterion=\"gini\", random_state=42)\n",
    "        tree_clf_entropy = DecisionTreeClassifier(max_depth = i, criterion=\"entropy\", random_state=42)\n",
    "    \n",
    "        tree_clf_gini.fit(X_train, y_train)\n",
    "        tree_clf_entropy.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred_gini = tree_clf_gini.predict(X_test)\n",
    "        y_pred_entropy = tree_clf_entropy.predict(X_test)  \n",
    "        \n",
    "    \n",
    "        result_metrics_dict_gini = classification_report(y_test, y_pred_gini, target_names=target_names, output_dict=True)\n",
    "        result_metrics_dict_entropy = classification_report(y_test, y_pred_entropy, target_names=target_names, output_dict=True)\n",
    "    \n",
    "        precision_sum_gini += result_metrics_dict_gini[\"macro avg\"][\"precision\"]\n",
    "        recall_sum_gini += result_metrics_dict_gini[\"macro avg\"][\"recall\"]\n",
    "        accuracy_sum_gini += result_metrics_dict_gini[\"accuracy\"]\n",
    "        \n",
    "        precision_sum_entropy += result_metrics_dict_entropy[\"macro avg\"][\"precision\"]\n",
    "        recall_sum_entropy += result_metrics_dict_entropy[\"macro avg\"][\"recall\"]\n",
    "        accuracy_sum_entropy += result_metrics_dict_entropy[\"accuracy\"]\n",
    "        \n",
    "    print(\"Results for K = \", k, \"\\n\")\n",
    "    \n",
    "    print(\"Average precision (GINI):\", precision_sum_gini/kf.get_n_splits(X))\n",
    "    print(\"Average recall (GINI):\", recall_sum_gini/kf.get_n_splits(X))\n",
    "    print(\"Average accuracy (GINI):\", accuracy_sum_gini/kf.get_n_splits(X), \"\\n\")\n",
    "    \n",
    "    print(\"Average precision (ENTROPY):\", precision_sum_entropy/kf.get_n_splits(X))\n",
    "    print(\"Average recall (ENTROPY):\", recall_sum_entropy/kf.get_n_splits(X))\n",
    "    print(\"Average accuracy (ENTROPY):\", accuracy_sum_entropy/kf.get_n_splits(X), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The performance of the gini and entropy classifiers was actually fairly similar on the same testing set, and the best performing depth appeared to be max depth = 3. Changing the value of K didn't change the results significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot important features\n",
    "def plot_feature_importances(clf, feature_names):\n",
    "    c_features = len(feature_names)\n",
    "    plt.barh(range(c_features), clf.feature_importances_)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature name\")\n",
    "    plt.yticks(np.arange(c_features), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DT classifier on training set: 1.00\n",
      "Accuracy of DT classifier on test set: 0.74\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Find the important features of the entropy DT model\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf1.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf1.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=60)\n",
    "\n",
    "# call the function above\n",
    "plot_feature_importances(clf1, X.columns.values.tolist())\n",
    "plt.show()\n",
    "\n",
    "print('Feature importances: {}'.format(tree_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will consider entropy Decision Tree with max depth = 3 and K = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 80% for training, 20% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1\n",
      "[[2179  547]\n",
      " [ 634  963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.77      0.80      0.79      2726\n",
      "        Over       0.64      0.60      0.62      1597\n",
      "\n",
      "    accuracy                           0.73      4323\n",
      "   macro avg       0.71      0.70      0.70      4323\n",
      "weighted avg       0.72      0.73      0.73      4323\n",
      "\n",
      "k=5\n",
      "[[2355  371]\n",
      " [ 617  980]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.86      0.83      2726\n",
      "        Over       0.73      0.61      0.66      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.76      0.74      0.75      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=15\n",
      "[[2364  362]\n",
      " [ 615  982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      2726\n",
      "        Over       0.73      0.61      0.67      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.76      0.74      0.75      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=20\n",
      "[[2422  304]\n",
      " [ 675  922]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.89      0.83      2726\n",
      "        Over       0.75      0.58      0.65      1597\n",
      "\n",
      "    accuracy                           0.77      4323\n",
      "   macro avg       0.77      0.73      0.74      4323\n",
      "weighted avg       0.77      0.77      0.77      4323\n",
      "\n",
      "k=25\n",
      "[[2389  337]\n",
      " [ 619  978]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.88      0.83      2726\n",
      "        Over       0.74      0.61      0.67      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.74      0.75      4323\n",
      "weighted avg       0.78      0.78      0.77      4323\n",
      "\n",
      "k=30\n",
      "[[2417  309]\n",
      " [ 658  939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.89      0.83      2726\n",
      "        Over       0.75      0.59      0.66      1597\n",
      "\n",
      "    accuracy                           0.78      4323\n",
      "   macro avg       0.77      0.74      0.75      4323\n",
      "weighted avg       0.77      0.78      0.77      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the best k value\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_value = [1, 5, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_value:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(f\"k={k}\")\n",
    "    \n",
    "    # plot a confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_mat)\n",
    "    \n",
    "    # Print classification report\n",
    "    target_names = ['Under', 'Over']\n",
    "   \n",
    "    #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    result_metrics = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    print(result_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Performance with k = 1 *******\n",
      "Precision:  0.7223142849111975\n",
      "Recall:  0.7227132213668531\n",
      "Accuracy:  0.7227132213668531\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 3 *******\n",
      "Precision:  0.7511881853068534\n",
      "Recall:  0.7540831468060191\n",
      "Accuracy:  0.7540831468060191\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 5 *******\n",
      "Precision:  0.7602495682267002\n",
      "Recall:  0.7638456120260123\n",
      "Accuracy:  0.7638456120260123\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 10 *******\n",
      "Precision:  0.7648813509063372\n",
      "Recall:  0.7683338207639805\n",
      "Accuracy:  0.7683338207639805\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 15 *******\n",
      "Precision:  0.7684567991363468\n",
      "Recall:  0.7722666603987838\n",
      "Accuracy:  0.7722666603987838\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 20 *******\n",
      "Precision:  0.769176734786725\n",
      "Recall:  0.7728220102359152\n",
      "Accuracy:  0.7728220102359152\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 25 *******\n",
      "Precision:  0.7699248850820828\n",
      "Recall:  0.773747550484393\n",
      "Accuracy:  0.773747550484393\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 30 *******\n",
      "Precision:  0.7692727312506377\n",
      "Recall:  0.7729144422425508\n",
      "Accuracy:  0.7729144422425508\n",
      "**************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-Cross validation (k=3) on the original data\n",
    "# KNN classifier with varying k values\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into k folds \n",
    "\n",
    "k_values = [1, 3, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_values:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "        \n",
    "        #print(f\"k={k}\")\n",
    "        #print(\"training score: \", knn.score(X_train, y_train))\n",
    "        #print(\"testing score: \", knn.score(X_test, y_test))\n",
    "    \n",
    "        # plot a confusion matrix\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "        #print(confusion_mat)\n",
    "    \n",
    "        #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        results = classification_report(y_test, y_pred, target_names=target_names)\n",
    "        #print(results)\n",
    "\n",
    "        metrics_dict = classification_report(y_test, y_pred, \n",
    "                        target_names=target_names, output_dict=True)\n",
    "\n",
    "        avg_precision = metrics_dict['weighted avg']['precision']\n",
    "        #print('precision (weighted):', avg_precision)\n",
    "        precision.append(avg_precision)\n",
    "    \n",
    "        avg_recall = metrics_dict['weighted avg']['recall']\n",
    "        #print('recall avg (weighted):', avg_recall)\n",
    "        recall.append(avg_recall)\n",
    "    \n",
    "        avg_accuracy = metrics_dict['accuracy']\n",
    "        #print('accuracy: ', avg_accuracy)\n",
    "        accuracy.append(avg_accuracy)\n",
    "        \n",
    "    print('\\n******* Performance with k =', k, '*******')\n",
    "    print('Precision: ', sum(precision)/len(precision))\n",
    "    print('Recall: ', sum(recall)/len(recall))\n",
    "    print('Accuracy: ', sum(accuracy)/len(accuracy))\n",
    "    print('**************************************\\n')\n",
    "    \n",
    "    plt.plot(k, np.mean(test_score), 'bo')\n",
    "    plt.plot(k, np.mean(train_score), 'rx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 30 is best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  most_recent\n",
      "0         3       1.00         1180      5650         1955\n",
      "1         3       2.25         2570      7242         1991\n",
      "2         2       1.00          770     10000         1933\n",
      "3         4       3.00         1960      5000         1965\n",
      "4         3       2.00         1680      8080         1987\n",
      "   bedrooms  bathrooms  sqft_living  sqft_lot  most_recent\n",
      "0  0.090909    0.12500     0.067170  0.003108     0.478261\n",
      "1  0.090909    0.28125     0.172075  0.004072     0.791304\n",
      "2  0.060606    0.12500     0.036226  0.005743     0.286957\n",
      "3  0.121212    0.37500     0.126038  0.002714     0.565217\n",
      "4  0.090909    0.25000     0.104906  0.004579     0.756522\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "print(data.head())\n",
    "\n",
    "# normalized\n",
    "min_max = preprocessing.MinMaxScaler()\n",
    "\n",
    "col = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']\n",
    "normData = min_max.fit_transform(data)\n",
    "\n",
    "normData = pd.DataFrame(normData, columns = col)\n",
    "print(normData.head())\n",
    "\n",
    "X_normalized = normData.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Performance with k = 1 *******\n",
      "Precision:  0.7192233709132082\n",
      "Recall:  0.719798174170851\n",
      "Accuracy:  0.719798174170851\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 3 *******\n",
      "Precision:  0.7497055512989208\n",
      "Recall:  0.7528339050849869\n",
      "Accuracy:  0.7528339050849869\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 5 *******\n",
      "Precision:  0.7635897619206857\n",
      "Recall:  0.7671307918352605\n",
      "Accuracy:  0.7671307918352605\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 10 *******\n",
      "Precision:  0.7668028331983016\n",
      "Recall:  0.7701847920867465\n",
      "Accuracy:  0.7701847920867465\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 15 *******\n",
      "Precision:  0.7709354430588234\n",
      "Recall:  0.7747187897642904\n",
      "Accuracy:  0.7747187897642904\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 20 *******\n",
      "Precision:  0.7681464613833189\n",
      "Recall:  0.7718040122927569\n",
      "Accuracy:  0.7718040122927569\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 25 *******\n",
      "Precision:  0.7720678326921595\n",
      "Recall:  0.7757831032519394\n",
      "Accuracy:  0.7757831032519394\n",
      "**************************************\n",
      "\n",
      "\n",
      "******* Performance with k = 30 *******\n",
      "Precision:  0.7706789236262731\n",
      "Recall:  0.7743489011874685\n",
      "Accuracy:  0.7743489011874685\n",
      "**************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-Cross Validation on the normalized data\n",
    "# KNN classifier with varying k values\n",
    "\n",
    "k_values = [1, 3, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "for k in k_values:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X_normalized):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        train_score.append(knn.score(X_train, y_train))\n",
    "        test_score.append(knn.score(X_test, y_test))\n",
    "        \n",
    "        #print(f\"k={k}\")\n",
    "        #print(\"training score: \", knn.score(X_train, y_train))\n",
    "        #print(\"testing score: \", knn.score(X_test, y_test))\n",
    "    \n",
    "        # plot a confusion matrix\n",
    "        confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "        #print(confusion_mat)\n",
    "    \n",
    "        #classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        results = classification_report(y_test, y_pred, target_names=target_names)\n",
    "        #print(results)\n",
    "\n",
    "        metrics_dict = classification_report(y_test, y_pred, \n",
    "                        target_names=target_names, output_dict=True)\n",
    "\n",
    "        avg_precision = metrics_dict['weighted avg']['precision']\n",
    "        #print('precision (weighted):', avg_precision)\n",
    "        precision.append(avg_precision)\n",
    "    \n",
    "        avg_recall = metrics_dict['weighted avg']['recall']\n",
    "        #print('recall avg (weighted):', avg_recall)\n",
    "        recall.append(avg_recall)\n",
    "    \n",
    "        avg_accuracy = metrics_dict['accuracy']\n",
    "        #print('accuracy: ', avg_accuracy)\n",
    "        accuracy.append(avg_accuracy)\n",
    "        \n",
    "    print('\\n******* Performance with k =', k, '*******')\n",
    "    print('Precision: ', sum(precision)/len(precision))\n",
    "    print('Recall: ', sum(recall)/len(recall))\n",
    "    print('Accuracy: ', sum(accuracy)/len(accuracy))\n",
    "    print('**************************************\\n')\n",
    "    \n",
    "    plt.plot(k, np.mean(test_score), 'bo')\n",
    "    plt.plot(k, np.mean(train_score), 'rx')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized vs non-normalized data does not change much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.88      0.83      1379\n",
      "        Over       0.74      0.60      0.66       783\n",
      "\n",
      "    accuracy                           0.78      2162\n",
      "   macro avg       0.77      0.74      0.75      2162\n",
      "weighted avg       0.77      0.78      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1383\n",
      "        Over       0.73      0.60      0.66       779\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.76      0.74      0.74      2162\n",
      "weighted avg       0.77      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.88      0.83      1354\n",
      "        Over       0.75      0.59      0.66       808\n",
      "\n",
      "    accuracy                           0.77      2162\n",
      "   macro avg       0.77      0.74      0.75      2162\n",
      "weighted avg       0.77      0.77      0.77      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1368\n",
      "        Over       0.73      0.61      0.67       793\n",
      "\n",
      "    accuracy                           0.78      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.78      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.87      0.82      1366\n",
      "        Over       0.72      0.57      0.64       795\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.75      0.72      0.73      2161\n",
      "weighted avg       0.76      0.76      0.75      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.89      0.84      1390\n",
      "        Over       0.75      0.61      0.67       771\n",
      "\n",
      "    accuracy                           0.79      2161\n",
      "   macro avg       0.78      0.75      0.76      2161\n",
      "weighted avg       0.78      0.79      0.78      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.80      0.88      0.84      1373\n",
      "        Over       0.75      0.62      0.68       788\n",
      "\n",
      "    accuracy                           0.79      2161\n",
      "   macro avg       0.78      0.75      0.76      2161\n",
      "weighted avg       0.78      0.79      0.78      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1376\n",
      "        Over       0.73      0.60      0.66       785\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.74      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.79      0.87      0.83      1361\n",
      "        Over       0.74      0.60      0.66       800\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.78      0.87      0.83      1344\n",
      "        Over       0.75      0.60      0.67       817\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.76      0.74      0.75      2161\n",
      "weighted avg       0.77      0.77      0.77      2161\n",
      "\n",
      "Avg precision (weighted): 0.7722794030453511\n",
      "Avg recall (weighted): 0.7758756588604396\n",
      "Accuracy: 0.7758756588604396\n"
     ]
    }
   ],
   "source": [
    "# change DataFrame to numpy array\n",
    "XX = X.to_numpy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 30)\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) \n",
    "\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(XX):\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"weighted avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"weighted avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Avg precision (weighted):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Avg recall (weighted):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Accuracy:\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "\n",
    "# We start with k=10 and will increase it to 10.\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 10 folds \n",
    "\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "print (kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.74\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.77\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.74\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.77\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.76\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.74\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.77\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.76\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.76\n",
      "Accuracy of GaussianNB classifier on training set: 0.76\n",
      "Accuracy of GaussianNB classifier on test set: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Apply k-cross when k = 10\n",
    "nbclf = GaussianNB()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # for each iteration, get training data and test data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # train the model using training data\n",
    "    nbclf.fit(X_train, y_train)\n",
    "    \n",
    "    # show how model performs with training data and test data\n",
    "    print('Accuracy of GaussianNB classifier on training set: {:.2f}'\n",
    "         .format(nbclf.score(X_train, y_train)))\n",
    "\n",
    "    print('Accuracy of GaussianNB classifier on test set: {:.2f}'\n",
    "         .format(nbclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.75      0.92      0.83      1398\n",
      "        Over       0.75      0.43      0.55       764\n",
      "\n",
      "    accuracy                           0.75      2162\n",
      "   macro avg       0.75      0.68      0.69      2162\n",
      "weighted avg       0.75      0.75      0.73      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.76      0.93      0.83      1409\n",
      "        Over       0.76      0.44      0.56       753\n",
      "\n",
      "    accuracy                           0.76      2162\n",
      "   macro avg       0.76      0.68      0.70      2162\n",
      "weighted avg       0.76      0.76      0.74      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.74      0.92      0.82      1353\n",
      "        Over       0.78      0.47      0.59       809\n",
      "\n",
      "    accuracy                           0.75      2162\n",
      "   macro avg       0.76      0.70      0.71      2162\n",
      "weighted avg       0.76      0.75      0.74      2162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.74      0.93      0.82      1333\n",
      "        Over       0.80      0.47      0.59       828\n",
      "\n",
      "    accuracy                           0.75      2161\n",
      "   macro avg       0.77      0.70      0.70      2161\n",
      "weighted avg       0.76      0.75      0.73      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.76      0.92      0.83      1372\n",
      "        Over       0.78      0.51      0.62       789\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.77      0.71      0.72      2161\n",
      "weighted avg       0.77      0.77      0.75      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.76      0.92      0.83      1376\n",
      "        Over       0.78      0.48      0.60       785\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.77      0.70      0.71      2161\n",
      "weighted avg       0.77      0.76      0.75      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.73      0.94      0.83      1346\n",
      "        Over       0.82      0.44      0.57       815\n",
      "\n",
      "    accuracy                           0.75      2161\n",
      "   macro avg       0.78      0.69      0.70      2161\n",
      "weighted avg       0.77      0.75      0.73      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.75      0.93      0.83      1373\n",
      "        Over       0.79      0.46      0.58       788\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.77      0.70      0.71      2161\n",
      "weighted avg       0.76      0.76      0.74      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.75      0.93      0.83      1364\n",
      "        Over       0.79      0.46      0.59       797\n",
      "\n",
      "    accuracy                           0.76      2161\n",
      "   macro avg       0.77      0.70      0.71      2161\n",
      "weighted avg       0.77      0.76      0.74      2161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Under       0.76      0.93      0.83      1370\n",
      "        Over       0.80      0.48      0.60       791\n",
      "\n",
      "    accuracy                           0.77      2161\n",
      "   macro avg       0.78      0.70      0.72      2161\n",
      "weighted avg       0.77      0.77      0.75      2161\n",
      "\n",
      "Avg precision: 0.7627995918625026\n",
      "Avg recall: 0.7573225598352084\n",
      "Accuracy: 0.7573225598352084\n"
     ]
    }
   ],
   "source": [
    "# Model performance using k-cross\n",
    "nbclf2 = GaussianNB()\n",
    "\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # for each iteration, get training data and test data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # train the model using training data\n",
    "    nbclf2.fit(X_train, y_train)\n",
    "    \n",
    "    # predict y values using test data\n",
    "    y_pred = nbclf2.predict(X_test)\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    #print(confusion_mat)\n",
    "    \n",
    "    # read to file\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    # Since we can retrieve a dictionary of metrics and access the values using dictionary,\n",
    "    # now we can sum of the results of each iteration and get the average\n",
    "    result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    #print(result_metrics_dict)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"weighted avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"weighted avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Avg precision:\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Avg recall:\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Accuracy:\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8238334646095498\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "y_score = nbclf2.predict_proba(X_test)\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_score[:,1])\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print('Accuracy = ', roc_auc)\n",
    "\n",
    "# Plotting\n",
    "plt.title('ROC')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label=('Accuracy = %0.2f'%roc_auc))\n",
    "plt.legend(loc='lower right', prop={'size':8})\n",
    "plt.plot([0,1],[0,1], color='lightgrey', linestyle='--')\n",
    "plt.xlim([-0.05,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
