{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and training-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "0           0  7129300520  20141013T000000  221900.0         3       1.00   \n",
      "1           1  6414100192  20141209T000000  538000.0         3       2.25   \n",
      "2           2  5631500400  20150225T000000  180000.0         2       1.00   \n",
      "3           3  2487200875  20141209T000000  604000.0         4       3.00   \n",
      "4           4  1954400510  20150218T000000  510000.0         3       2.00   \n",
      "\n",
      "   sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "0         1180      5650     1.0           0  ...      1955             0   \n",
      "1         2570      7242     2.0           0  ...      1951          1991   \n",
      "2          770     10000     1.0           0  ...      1933             0   \n",
      "3         1960      5000     1.0           0  ...      1965             0   \n",
      "4         1680      8080     1.0           0  ...      1987             0   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "0    98178  47.5112 -122.257           1340        5650  2014-10-13   \n",
      "1    98125  47.7210 -122.319           1690        7639  2014-12-09   \n",
      "2    98028  47.7379 -122.233           2720        8062  2015-02-25   \n",
      "3    98136  47.5208 -122.393           1360        5000  2014-12-09   \n",
      "4    98074  47.6168 -122.045           1800        7503  2015-02-18   \n",
      "\n",
      "   most_recent  price_range  \n",
      "0         1955            0  \n",
      "1         1991            0  \n",
      "2         1933            0  \n",
      "3         1965            1  \n",
      "4         1987            0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "       Unnamed: 0          id             date     price  bedrooms  bathrooms  \\\n",
      "21608       21608   263000018  20140521T000000  360000.0         3       2.50   \n",
      "21609       21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
      "21610       21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
      "21611       21611   291310100  20150116T000000  400000.0         3       2.50   \n",
      "21612       21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
      "\n",
      "       sqft_living  sqft_lot  floors  waterfront  ...  yr_built  yr_renovated  \\\n",
      "21608         1530      1131     3.0           0  ...      2009             0   \n",
      "21609         2310      5813     2.0           0  ...      2014             0   \n",
      "21610         1020      1350     2.0           0  ...      2009             0   \n",
      "21611         1600      2388     2.0           0  ...      2004             0   \n",
      "21612         1020      1076     2.0           0  ...      2008             0   \n",
      "\n",
      "       zipcode      lat     long  sqft_living15  sqft_lot15   date_time  \\\n",
      "21608    98103  47.6993 -122.346           1530        1509  2014-05-21   \n",
      "21609    98146  47.5107 -122.362           1830        7200  2015-02-23   \n",
      "21610    98144  47.5944 -122.299           1020        2007  2014-06-23   \n",
      "21611    98027  47.5345 -122.069           1410        1287  2015-01-16   \n",
      "21612    98144  47.5941 -122.299           1020        1357  2014-10-15   \n",
      "\n",
      "       most_recent  price_range  \n",
      "21608         2009            0  \n",
      "21609         2014            0  \n",
      "21610         2009            0  \n",
      "21611         2004            0  \n",
      "21612         2008            0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read data from CSV file to dataframe\n",
    "df = pd.read_csv(r\"C:\\Users\\marik\\Documents\\GitHub\\CPSC4310-MLP\\input\\kc_sales_cleaned.csv\")\n",
    "\n",
    "# make sure you understand the type of the object\n",
    "print(type(df))\n",
    "\n",
    "# check the top five and the botoom five data tuples\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# split the data 70% for training, 30% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Decision tree – information gain (entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\\n                9,\\n            ...\\n            21603, 21604, 21605, 21606, 21607, 21608, 21609, 21610, 21611,\\n            21612],\\n           dtype='int64', length=19451)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/2229649540.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\\n                9,\\n            ...\\n            21603, 21604, 21605, 21606, 21607, 21608, 21609, 21610, 21611,\\n            21612],\\n           dtype='int64', length=19451)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "# decision tree classifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='entropy', random_state=42)\n",
    "\n",
    "# k-fold cross validation (k=10)\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 2 folds\n",
    "\n",
    "# each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    target_names = df['price_range'].target_names\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# change this\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "# A simple training (1 training)\n",
    "# # split the data 70% for training, 30% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 3, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='entropy')\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 2 folds \n",
    "\n",
    "# each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # Print classification report for each fold\n",
    "    target_names = iris.target_names\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "y = df['price_range']\n",
    "\n",
    "# default is 75% / 25% train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7672094744633605"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2914  565]\n",
      " [ 693 1232]]\n",
      "accuracy:  0.7672094744633605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.84      0.82      3479\n",
      "           0       0.69      0.64      0.66      1925\n",
      "\n",
      "    accuracy                           0.77      5404\n",
      "   macro avg       0.75      0.74      0.74      5404\n",
      "weighted avg       0.76      0.77      0.77      5404\n",
      "\n",
      "precision (weighted): 0.7643129773013678\n",
      "recall avg (weighted): 0.7672094744633605\n",
      "accuracy:  0.7672094744633605\n"
     ]
    }
   ],
   "source": [
    "# plot a confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(confusion_mat)\n",
    "\n",
    "correct = confusion_mat[0, 0]+confusion_mat[1, 1]\n",
    "print('accuracy: ', correct/confusion_mat.sum())\n",
    "#plot_confusion_matrix(confusion_mat, 4)\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "target_names = ['1', '0']\n",
    "\n",
    "result_metrics = classification_report(y_test, y_pred, target_names=target_names)\n",
    "\n",
    "print(result_metrics)\n",
    "\n",
    "metrics_dict = classification_report(y_test, y_pred, \n",
    "                            target_names=target_names, output_dict=True)\n",
    "    \n",
    "print('precision (weighted):', metrics_dict['weighted avg']['precision'])\n",
    "print('recall avg (weighted):', metrics_dict['weighted avg']['recall'])\n",
    "print('accuracy: ', metrics_dict['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "# create k-fold validation\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into 3 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg precision (weighted): 0.7521312907858086\n",
      "Avg recall (weighted): 0.7553784664571292\n",
      "Accuracy: 0.7553784664571292\n"
     ]
    }
   ],
   "source": [
    "# change DataFrame to numpy array\n",
    "XX = X.to_numpy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "precision_sum = recall_sum = accuracy_sum = 0\n",
    "\n",
    "for train_index, test_index in kf.split(XX):\n",
    "    X_train, X_test = XX[train_index], XX[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    result_metrics_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    precision_sum += result_metrics_dict[\"weighted avg\"][\"precision\"]\n",
    "    recall_sum += result_metrics_dict[\"weighted avg\"][\"recall\"]\n",
    "    accuracy_sum += result_metrics_dict[\"accuracy\"]\n",
    "\n",
    "print(\"Avg precision (weighted):\", precision_sum/kf.get_n_splits(X))\n",
    "print(\"Avg recall (weighted):\", recall_sum/kf.get_n_splits(X))\n",
    "print(\"Accuracy:\", accuracy_sum/kf.get_n_splits(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Naive Bayes classifier or logistic regression??? idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
