{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP4\n",
    "\n",
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"NN_deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)\n",
    "\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import tensorflow and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c0e1762d7f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read data from CSV file to dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"./input/kc_sales_cleaned.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# read data from CSV file to dataframe\n",
    "df = pd.read_csv(r\"./input/kc_sales_cleaned.csv\")\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick view of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 25 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     21613 non-null  int64  \n",
      " 1   id             21613 non-null  int64  \n",
      " 2   date           21613 non-null  object \n",
      " 3   price          21613 non-null  float64\n",
      " 4   bedrooms       21613 non-null  int64  \n",
      " 5   bathrooms      21613 non-null  float64\n",
      " 6   sqft_living    21613 non-null  int64  \n",
      " 7   sqft_lot       21613 non-null  int64  \n",
      " 8   floors         21613 non-null  float64\n",
      " 9   waterfront     21613 non-null  int64  \n",
      " 10  view           21613 non-null  int64  \n",
      " 11  condition      21613 non-null  int64  \n",
      " 12  grade          21613 non-null  int64  \n",
      " 13  sqft_above     21613 non-null  int64  \n",
      " 14  sqft_basement  21613 non-null  int64  \n",
      " 15  yr_built       21613 non-null  int64  \n",
      " 16  yr_renovated   21613 non-null  int64  \n",
      " 17  zipcode        21613 non-null  int64  \n",
      " 18  lat            21613 non-null  float64\n",
      " 19  long           21613 non-null  float64\n",
      " 20  sqft_living15  21613 non-null  int64  \n",
      " 21  sqft_lot15     21613 non-null  int64  \n",
      " 22  date_time      21613 non-null  object \n",
      " 23  most_recent    21613 non-null  int64  \n",
      " 24  price_range    21613 non-null  int64  \n",
      "dtypes: float64(5), int64(18), object(2)\n",
      "memory usage: 4.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  most_recent\n",
      "0         3       1.00         1180      5650         1955\n",
      "1         3       2.25         2570      7242         1991\n",
      "2         2       1.00          770     10000         1933\n",
      "3         4       3.00         1960      5000         1965\n",
      "4         3       2.00         1680      8080         1987\n",
      "[[3.000e+00 1.000e+00 1.180e+03 5.650e+03 1.955e+03]\n",
      " [3.000e+00 2.250e+00 2.570e+03 7.242e+03 1.991e+03]\n",
      " [2.000e+00 1.000e+00 7.700e+02 1.000e+04 1.933e+03]\n",
      " [4.000e+00 3.000e+00 1.960e+03 5.000e+03 1.965e+03]\n",
      " [3.000e+00 2.000e+00 1.680e+03 8.080e+03 1.987e+03]]\n",
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Import `train_test_split` from `sklearn.model_selection`\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the data \n",
    "\n",
    "# We use bedrooms, bathrooms, sqft_living, sqft_lot, and 'most_recent' attributes\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'most_recent']]\n",
    "#y = df['price_range']\n",
    "\n",
    "print(X[:5])\n",
    "\n",
    "X = X.values\n",
    "\n",
    "# Specify the target labels and flatten the array\n",
    "y = np.ravel(df.price_range)\n",
    "\n",
    "# first 5 row data for X (attributes) and y (class label)\n",
    "print(X[:10][:5])\n",
    "print(y[:5])\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `StandardScaler` from `sklearn.preprocessing`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the train set\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Scale the test set\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction\n",
    "\n",
    "- input layer (5 attributes = 5 units)\n",
    "- 2 hidden layer (6 units, 6 units)\n",
    "- output layer (1 unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add the first hidden layer and specify the shape of input layer\n",
    "model.add(keras.layers.Dense(6, activation='relu', input_shape=(5,)))\n",
    "\n",
    "# Add 2nd hidden hidden later\n",
    "model.add(keras.layers.Dense(6, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### information about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6)                 36        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85\n",
      "Trainable params: 85\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.4781261 , -0.33778715,  0.22476727, -0.15862119,  0.1565783 ,\n",
       "         -0.10338265],\n",
       "        [ 0.11039698, -0.15762597,  0.60052377, -0.54928106,  0.03220803,\n",
       "          0.46672982],\n",
       "        [ 0.20325297, -0.5031246 , -0.72721124,  0.5446814 , -0.44708326,\n",
       "          0.6209782 ],\n",
       "        [-0.13168478,  0.7341998 ,  0.6920554 , -0.15457183, -0.46402144,\n",
       "         -0.0337373 ],\n",
       "        [-0.48461902,  0.55005676, -0.04535109,  0.43749827, -0.7269376 ,\n",
       "          0.6717933 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.59263796,  0.20407099, -0.36138645, -0.63948584, -0.43124217,\n",
       "         -0.59066045],\n",
       "        [-0.5717014 , -0.33579034, -0.6152093 , -0.54454756, -0.38181537,\n",
       "          0.30511564],\n",
       "        [-0.0787273 , -0.64018077, -0.5137613 , -0.409007  ,  0.25725543,\n",
       "          0.42909485],\n",
       "        [ 0.63762814,  0.45585698,  0.12942135, -0.5963216 , -0.16481507,\n",
       "          0.31138903],\n",
       "        [-0.4039988 , -0.00677437,  0.40279406,  0.6677291 , -0.11966401,\n",
       "          0.22145605],\n",
       "        [-0.38895437,  0.0662297 , -0.5678037 , -0.52457553, -0.22617954,\n",
       "          0.60792476]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.33785903],\n",
       "        [-0.62796515],\n",
       "        [-0.14902437],\n",
       "        [-0.48462728],\n",
       "        [-0.59090745],\n",
       "        [-0.06399083]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the model and fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14480/14480 [==============================] - 39s 3ms/step - loss: 0.4708 - accuracy: 0.7731\n",
      "Epoch 2/3\n",
      "14480/14480 [==============================] - 39s 3ms/step - loss: 0.4469 - accuracy: 0.7870\n",
      "Epoch 3/3\n",
      "14480/14480 [==============================] - 37s 3ms/step - loss: 0.4459 - accuracy: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a90555c610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(X_train, y_train,epochs=3, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 1s 3ms/step\n",
      "[0 1 1 1 1]\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(y_test[:5])\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.7955\n",
      "[0.436940461397171, 0.7954577207565308]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3888  624]\n",
      " [ 835 1786]]\n",
      "precision: 0.7411\n",
      "recall: 0.6814\n",
      "f1 score: 0.7100\n"
     ]
    }
   ],
   "source": [
    "# Import the modules from `sklearn.metrics`\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Confusion matrix\n",
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cmatrix)\n",
    "\n",
    "# precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "\n",
    "print('precision: {:.4f}\\nrecall: {:.4f}\\nf1 score: {:.4f}'.format(precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
